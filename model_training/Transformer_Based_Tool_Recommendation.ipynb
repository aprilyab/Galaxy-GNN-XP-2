{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11539002",
   "metadata": {},
   "source": [
    "Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff0edbea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-22 17:41:48.084172: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Complete Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, Counter\n",
    "from typing import List, Dict, Set, Any, Optional, Tuple\n",
    "\n",
    "# TensorFlow/Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Set paths\n",
    "DATA_PATH = Path(\"../data/workflow_connections_simulated.tsv\")\n",
    "PROJECT_ROOT = Path(\"..\")\n",
    "OUTPUT_DIR = Path(\"../models/transformer_tool_recommendation\")\n",
    "PROCESSED_DIR = Path(\"../data/processed\")\n",
    "\n",
    "# Create directories\n",
    "OUTPUT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "PROCESSED_DIR.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de55a674",
   "metadata": {},
   "source": [
    "Data Loading and Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a12f512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Neo4j workflow connections...\n",
      "Dataset shape: (13316, 11)\n",
      "Unique workflows: 678\n",
      "Unique source tools: 1802\n",
      "Unique target tools: 2229\n",
      "\n",
      "Sample data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workflow_id</th>\n",
       "      <th>workflow_name</th>\n",
       "      <th>created_at</th>\n",
       "      <th>source_step_id</th>\n",
       "      <th>source_tool</th>\n",
       "      <th>source_tool_version</th>\n",
       "      <th>source_output_name</th>\n",
       "      <th>target_step_id</th>\n",
       "      <th>target_tool</th>\n",
       "      <th>target_tool_version</th>\n",
       "      <th>target_input_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00381f04ea14dae34ef20bc69e4b59e2</td>\n",
       "      <td>training:_16s_rrna_sequencing_with_mothur:_mai...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Input dataset collection</td>\n",
       "      <td>NaN</td>\n",
       "      <td>output</td>\n",
       "      <td>6</td>\n",
       "      <td>3d54e34c5741c1e60229298df2f0cd4e</td>\n",
       "      <td>1.39.5.0</td>\n",
       "      <td>input_type|list_paired_collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00381f04ea14dae34ef20bc69e4b59e2</td>\n",
       "      <td>training:_16s_rrna_sequencing_with_mothur:_mai...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Input dataset</td>\n",
       "      <td>NaN</td>\n",
       "      <td>output</td>\n",
       "      <td>11</td>\n",
       "      <td>80adb20201077d72ad12231623c24fa2</td>\n",
       "      <td>1.39.5.0</td>\n",
       "      <td>alignment|reference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00381f04ea14dae34ef20bc69e4b59e2</td>\n",
       "      <td>training:_16s_rrna_sequencing_with_mothur:_mai...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>53e3f25e04a6602c4f73b129d6796364</td>\n",
       "      <td>1.39.5.0</td>\n",
       "      <td>seq_count</td>\n",
       "      <td>12</td>\n",
       "      <td>8bda04fd3cfd0b94863de5e6136effe1</td>\n",
       "      <td>1.39.5.0</td>\n",
       "      <td>count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00381f04ea14dae34ef20bc69e4b59e2</td>\n",
       "      <td>training:_16s_rrna_sequencing_with_mothur:_mai...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>53e3f25e04a6602c4f73b129d6796364</td>\n",
       "      <td>1.39.5.0</td>\n",
       "      <td>seq_count</td>\n",
       "      <td>13</td>\n",
       "      <td>8f1d1e8d7c383b7ed0f2343467e5e9a5</td>\n",
       "      <td>1.39.5.0</td>\n",
       "      <td>count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00381f04ea14dae34ef20bc69e4b59e2</td>\n",
       "      <td>training:_16s_rrna_sequencing_with_mothur:_mai...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>80adb20201077d72ad12231623c24fa2</td>\n",
       "      <td>1.39.5.0</td>\n",
       "      <td>out_align</td>\n",
       "      <td>12</td>\n",
       "      <td>8bda04fd3cfd0b94863de5e6136effe1</td>\n",
       "      <td>1.39.5.0</td>\n",
       "      <td>fasta</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        workflow_id  \\\n",
       "0  00381f04ea14dae34ef20bc69e4b59e2   \n",
       "1  00381f04ea14dae34ef20bc69e4b59e2   \n",
       "2  00381f04ea14dae34ef20bc69e4b59e2   \n",
       "3  00381f04ea14dae34ef20bc69e4b59e2   \n",
       "4  00381f04ea14dae34ef20bc69e4b59e2   \n",
       "\n",
       "                                       workflow_name  created_at  \\\n",
       "0  training:_16s_rrna_sequencing_with_mothur:_mai...         NaN   \n",
       "1  training:_16s_rrna_sequencing_with_mothur:_mai...         NaN   \n",
       "2  training:_16s_rrna_sequencing_with_mothur:_mai...         NaN   \n",
       "3  training:_16s_rrna_sequencing_with_mothur:_mai...         NaN   \n",
       "4  training:_16s_rrna_sequencing_with_mothur:_mai...         NaN   \n",
       "\n",
       "   source_step_id                       source_tool source_tool_version  \\\n",
       "0               0          Input dataset collection                 NaN   \n",
       "1               1                     Input dataset                 NaN   \n",
       "2              10  53e3f25e04a6602c4f73b129d6796364            1.39.5.0   \n",
       "3              10  53e3f25e04a6602c4f73b129d6796364            1.39.5.0   \n",
       "4              11  80adb20201077d72ad12231623c24fa2            1.39.5.0   \n",
       "\n",
       "  source_output_name  target_step_id                       target_tool  \\\n",
       "0             output               6  3d54e34c5741c1e60229298df2f0cd4e   \n",
       "1             output              11  80adb20201077d72ad12231623c24fa2   \n",
       "2          seq_count              12  8bda04fd3cfd0b94863de5e6136effe1   \n",
       "3          seq_count              13  8f1d1e8d7c383b7ed0f2343467e5e9a5   \n",
       "4          out_align              12  8bda04fd3cfd0b94863de5e6136effe1   \n",
       "\n",
       "  target_tool_version                  target_input_name  \n",
       "0            1.39.5.0  input_type|list_paired_collection  \n",
       "1            1.39.5.0                alignment|reference  \n",
       "2            1.39.5.0                              count  \n",
       "3            1.39.5.0                              count  \n",
       "4            1.39.5.0                              fasta  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13316 entries, 0 to 13315\n",
      "Data columns (total 11 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   workflow_id          13316 non-null  object \n",
      " 1   workflow_name        13316 non-null  object \n",
      " 2   created_at           0 non-null      float64\n",
      " 3   source_step_id       13316 non-null  int64  \n",
      " 4   source_tool          13316 non-null  object \n",
      " 5   source_tool_version  9379 non-null   object \n",
      " 6   source_output_name   13316 non-null  object \n",
      " 7   target_step_id       13316 non-null  int64  \n",
      " 8   target_tool          13316 non-null  object \n",
      " 9   target_tool_version  12920 non-null  object \n",
      " 10  target_input_name    13316 non-null  object \n",
      "dtypes: float64(1), int64(2), object(8)\n",
      "memory usage: 1.1+ MB\n",
      "None\n",
      "\n",
      "Workflow statistics:\n",
      "Average connections per workflow: 19.64\n",
      "Average unique tools per workflow: 7.74\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Neo4j workflow connections...\")\n",
    "df = pd.read_csv(DATA_PATH, sep='\\t')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Unique workflows: {df['workflow_id'].nunique()}\")\n",
    "print(f\"Unique source tools: {df['source_tool'].nunique()}\")\n",
    "print(f\"Unique target tools: {df['target_tool'].nunique()}\")\n",
    "\n",
    "# Display sample data and basic statistics\n",
    "print(\"Sample data:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"Column information:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"Workflow statistics:\")\n",
    "workflow_stats = df.groupby('workflow_id').agg({\n",
    "    'source_step_id': 'count',\n",
    "    'source_tool': 'nunique'\n",
    "}).rename(columns={'source_step_id': 'num_connections', 'source_tool': 'unique_tools'})\n",
    "\n",
    "print(f\"Average connections per workflow: {workflow_stats['num_connections'].mean():.2f}\")\n",
    "print(f\"Average unique tools per workflow: {workflow_stats['unique_tools'].mean():.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6904df79",
   "metadata": {},
   "source": [
    "Tool ID Cleaning and Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dfed540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced tool ID cleaning with input dataset handling...\n",
      "\n",
      "Cleaning results with input handling:\n",
      "Sample cleaned tools:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_tool</th>\n",
       "      <th>source_tool_clean</th>\n",
       "      <th>target_tool</th>\n",
       "      <th>target_tool_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Input dataset collection</td>\n",
       "      <td>&lt;INPUT_DATA&gt;</td>\n",
       "      <td>3d54e34c5741c1e60229298df2f0cd4e</td>\n",
       "      <td>tool_3d54e34c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Input dataset</td>\n",
       "      <td>&lt;INPUT_DATA&gt;</td>\n",
       "      <td>80adb20201077d72ad12231623c24fa2</td>\n",
       "      <td>tool_80adb202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53e3f25e04a6602c4f73b129d6796364</td>\n",
       "      <td>tool_53e3f25e</td>\n",
       "      <td>8bda04fd3cfd0b94863de5e6136effe1</td>\n",
       "      <td>tool_8bda04fd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53e3f25e04a6602c4f73b129d6796364</td>\n",
       "      <td>tool_53e3f25e</td>\n",
       "      <td>8f1d1e8d7c383b7ed0f2343467e5e9a5</td>\n",
       "      <td>tool_8f1d1e8d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80adb20201077d72ad12231623c24fa2</td>\n",
       "      <td>tool_80adb202</td>\n",
       "      <td>8bda04fd3cfd0b94863de5e6136effe1</td>\n",
       "      <td>tool_8bda04fd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>80adb20201077d72ad12231623c24fa2</td>\n",
       "      <td>tool_80adb202</td>\n",
       "      <td>8f1d1e8d7c383b7ed0f2343467e5e9a5</td>\n",
       "      <td>tool_8f1d1e8d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8f1d1e8d7c383b7ed0f2343467e5e9a5</td>\n",
       "      <td>tool_8f1d1e8d</td>\n",
       "      <td>3e6f19059695525da532a46e2d772810</td>\n",
       "      <td>tool_3e6f1905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8f1d1e8d7c383b7ed0f2343467e5e9a5</td>\n",
       "      <td>tool_8f1d1e8d</td>\n",
       "      <td>517cd25a7a1e50a2ce8c367e56012980</td>\n",
       "      <td>tool_517cd25a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3e6f19059695525da532a46e2d772810</td>\n",
       "      <td>tool_3e6f1905</td>\n",
       "      <td>517cd25a7a1e50a2ce8c367e56012980</td>\n",
       "      <td>tool_517cd25a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>517cd25a7a1e50a2ce8c367e56012980</td>\n",
       "      <td>tool_517cd25a</td>\n",
       "      <td>28ff05c9bc0f5d022925dc2a45dfd8d5</td>\n",
       "      <td>tool_28ff05c9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        source_tool source_tool_clean  \\\n",
       "0          Input dataset collection      <INPUT_DATA>   \n",
       "1                     Input dataset      <INPUT_DATA>   \n",
       "2  53e3f25e04a6602c4f73b129d6796364     tool_53e3f25e   \n",
       "3  53e3f25e04a6602c4f73b129d6796364     tool_53e3f25e   \n",
       "4  80adb20201077d72ad12231623c24fa2     tool_80adb202   \n",
       "5  80adb20201077d72ad12231623c24fa2     tool_80adb202   \n",
       "6  8f1d1e8d7c383b7ed0f2343467e5e9a5     tool_8f1d1e8d   \n",
       "7  8f1d1e8d7c383b7ed0f2343467e5e9a5     tool_8f1d1e8d   \n",
       "8  3e6f19059695525da532a46e2d772810     tool_3e6f1905   \n",
       "9  517cd25a7a1e50a2ce8c367e56012980     tool_517cd25a   \n",
       "\n",
       "                        target_tool target_tool_clean  \n",
       "0  3d54e34c5741c1e60229298df2f0cd4e     tool_3d54e34c  \n",
       "1  80adb20201077d72ad12231623c24fa2     tool_80adb202  \n",
       "2  8bda04fd3cfd0b94863de5e6136effe1     tool_8bda04fd  \n",
       "3  8f1d1e8d7c383b7ed0f2343467e5e9a5     tool_8f1d1e8d  \n",
       "4  8bda04fd3cfd0b94863de5e6136effe1     tool_8bda04fd  \n",
       "5  8f1d1e8d7c383b7ed0f2343467e5e9a5     tool_8f1d1e8d  \n",
       "6  3e6f19059695525da532a46e2d772810     tool_3e6f1905  \n",
       "7  517cd25a7a1e50a2ce8c367e56012980     tool_517cd25a  \n",
       "8  517cd25a7a1e50a2ce8c367e56012980     tool_517cd25a  \n",
       "9  28ff05c9bc0f5d022925dc2a45dfd8d5     tool_28ff05c9  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardizing Input datasets following GRU experiment approach...\n",
      "Input dataset standardization complete!\n",
      "Rows with <INPUT_DATA> as source: 3736\n",
      "Version distribution for <INPUT_DATA>: ['n/a']\n",
      "\n",
      "Rows with <INPUT_DATA>: 28.12%\n",
      "\n",
      "Workflow step count summary:\n",
      "count    678.000000\n",
      "mean      16.853982\n",
      "std       14.253173\n",
      "min        2.000000\n",
      "50%       12.000000\n",
      "75%       22.000000\n",
      "90%       35.300000\n",
      "95%       48.150000\n",
      "max       97.000000\n",
      "dtype: float64\n",
      "\n",
      "Top source tools after cleaning:\n",
      "source_tool_clean\n",
      "<INPUT_DATA>     3736\n",
      "tool_225a4f3a     271\n",
      "tool_69207e28     180\n",
      "tool_d7af1ce5     141\n",
      "tool_a15360c3     118\n",
      "tool_9293e990      97\n",
      "tool_d1f354f7      96\n",
      "tool_9644c093      88\n",
      "tool_bd5851dd      70\n",
      "tool_938e41c5      63\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Top target tools after cleaning:\n",
      "target_tool_clean\n",
      "tool_225a4f3a    261\n",
      "tool_1eea821d    154\n",
      "tool_69207e28    154\n",
      "tool_d7af1ce5    147\n",
      "tool_a980d106    106\n",
      "tool_d5a36e38     93\n",
      "tool_b8f7250f     93\n",
      "tool_a15360c3     93\n",
      "tool_9293e990     90\n",
      "tool_7f06f4e6     86\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique cleaned source tools: 1793\n",
      "Unique cleaned target tools: 2226\n",
      "Total unique cleaned tools: 2307\n",
      "\n",
      "Rows with <INPUT_DATA>: 3736\n",
      "Percentage of total: 28.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_86743/3442419791.py:82: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  wf_sizes = df.groupby('workflow_id').apply(\n"
     ]
    }
   ],
   "source": [
    "# Cell 3A: Enhanced Tool ID Cleaning with Input Dataset Handling\n",
    "def clean_tool_id(tool_id: str) -> str:\n",
    "    \"\"\"Enhanced cleaning with consistent input dataset handling\"\"\"\n",
    "    if pd.isna(tool_id):\n",
    "        return \"<UNK>\"\n",
    "    \n",
    "    tool_id = str(tool_id).strip()\n",
    "    \n",
    "    # Handle ALL input datasets consistently\n",
    "    input_keywords = [\n",
    "        \"input dataset\", \"input_parameter\", \"input_dataset_collection\",\n",
    "        \"input\", \"dataset\", \"collection\", \"parameter\"\n",
    "    ]\n",
    "    \n",
    "    if any(keyword in tool_id.lower() for keyword in input_keywords):\n",
    "        return \"<INPUT_DATA>\"\n",
    "    \n",
    "    # Handle hash-like IDs (32-character hex)\n",
    "    if re.match(r'^[a-f0-9]{32}$', tool_id):\n",
    "        return f\"tool_{tool_id[:8]}\"\n",
    "    \n",
    "    # Handle repository-style tool IDs\n",
    "    if \"/\" in tool_id:\n",
    "        parts = tool_id.split(\"/\")\n",
    "        if len(parts) >= 3:\n",
    "            tool_name = parts[-3] if parts[-3] != parts[-2] else parts[-2]\n",
    "            tool_name = re.sub(r'[^a-zA-Z0-9_]', '_', tool_name)\n",
    "            tool_name = re.sub(r'_+', '_', tool_name).strip('_')\n",
    "            return tool_name.lower() if tool_name else \"unknown_tool\"\n",
    "    \n",
    "    # Clean remaining special characters\n",
    "    cleaned = re.sub(r'[^a-zA-Z0-9_]', '_', tool_id)\n",
    "    cleaned = re.sub(r'_+', '_', cleaned).strip('_')\n",
    "    return cleaned.lower() if cleaned else \"unknown_tool\"\n",
    "\n",
    "# Apply enhanced cleaning\n",
    "print(\"Enhanced tool ID cleaning with input dataset handling...\")\n",
    "df['source_tool_clean'] = df['source_tool'].apply(clean_tool_id)\n",
    "df['target_tool_clean'] = df['target_tool'].apply(clean_tool_id)\n",
    "\n",
    "# Display cleaning results\n",
    "print(\"Cleaning results with input handling:\")\n",
    "print(\"Sample cleaned tools:\")\n",
    "sample_tools = df[['source_tool', 'source_tool_clean', 'target_tool', 'target_tool_clean']].head(10)\n",
    "display(sample_tools)\n",
    "\n",
    "# Count unique cleaned tools including input token\n",
    "unique_source_tools = df['source_tool_clean'].nunique()\n",
    "unique_target_tools = df['target_tool_clean'].nunique()\n",
    "all_clean_tools = set(df['source_tool_clean'].unique()) | set(df['target_tool_clean'].unique())\n",
    "\n",
    "# Cell 3B: Input Dataset Standardization (Following GRU Approach)\n",
    "print(\"Standardizing Input datasets following GRU experiment approach...\")\n",
    "\n",
    "# 1. Standardize \"Input\" token (already handled in cleaning, but double-check)\n",
    "df.loc[df[\"source_tool\"].astype(str).str.strip() == \"Input\", \"source_tool_clean\"] = \"<INPUT_DATA>\"\n",
    "df.loc[df[\"target_tool\"].astype(str).str.strip() == \"Input\", \"target_tool_clean\"] = \"<INPUT_DATA>\"\n",
    "\n",
    "# 2. Handle specific versioning for Input\n",
    "# Since it's not a tool, we assign \"n/a\" to indicate it represents dataset itself.\n",
    "mask_input_source = df[\"source_tool_clean\"] == \"<INPUT_DATA>\"\n",
    "df.loc[mask_input_source, \"source_tool_version\"] = df.loc[mask_input_source, \"source_tool_version\"].fillna(\"n/a\")\n",
    "\n",
    "mask_input_target = df[\"target_tool_clean\"] == \"<INPUT_DATA>\"\n",
    "df.loc[mask_input_target, \"target_tool_version\"] = df.loc[mask_input_target, \"target_tool_version\"].fillna(\"n/a\")\n",
    "\n",
    "# 3. Handle other missing versions (real tools with missing meta)\n",
    "df[\"source_tool_version\"] = df[\"source_tool_version\"].fillna(\"unknown\")\n",
    "df[\"target_tool_version\"] = df[\"target_tool_version\"].fillna(\"unknown\")\n",
    "\n",
    "# Verify cleanup\n",
    "print(\"Input dataset standardization complete!\")\n",
    "input_rows_clean = df[df[\"source_tool_clean\"] == \"<INPUT_DATA>\"]\n",
    "print(f\"Rows with <INPUT_DATA> as source: {len(input_rows_clean)}\")\n",
    "print(f\"Version distribution for <INPUT_DATA>: {input_rows_clean['source_tool_version'].unique()}\")\n",
    "\n",
    "# Display statistics\n",
    "input_ratio = ((df[\"source_tool_clean\"] == \"<INPUT_DATA>\") | (df[\"target_tool_clean\"] == \"<INPUT_DATA>\")).mean()\n",
    "print(f\"Rows with <INPUT_DATA>: {input_ratio:.2%}\")\n",
    "\n",
    "# Workflow sizes analysis\n",
    "wf_sizes = df.groupby('workflow_id').apply(\n",
    "    lambda df_group: len(pd.unique(df_group[[\"source_step_id\", \"target_step_id\"]].values.ravel()))\n",
    ")\n",
    "print(\"Workflow step count summary:\")\n",
    "print(wf_sizes.describe(percentiles=[0.5, 0.75, 0.9, 0.95]))\n",
    "\n",
    "# Top tools after cleaning\n",
    "print(\"Top source tools after cleaning:\")\n",
    "print(df[\"source_tool_clean\"].value_counts().head(10))\n",
    "print(\"Top target tools after cleaning:\")\n",
    "print(df[\"target_tool_clean\"].value_counts().head(10))\n",
    "\n",
    "print(f\"Unique cleaned source tools: {unique_source_tools}\")\n",
    "print(f\"Unique cleaned target tools: {unique_target_tools}\")\n",
    "print(f\"Total unique cleaned tools: {len(all_clean_tools)}\")\n",
    "\n",
    "# Check input dataset handling\n",
    "input_data_count = df[df['source_tool_clean'] == '<INPUT_DATA>'].shape[0]\n",
    "print(f\"Rows with <INPUT_DATA>: {input_data_count}\")\n",
    "print(f\"Percentage of total: {input_data_count/len(df)*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23a1d8d",
   "metadata": {},
   "source": [
    "Workflow Sequence Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "772533d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building workflow sequences...\n",
      "Generated 678 workflow sequences\n",
      "Average sequence length: 9.26\n",
      "Max sequence length: 36\n",
      "Min sequence length: 1\n",
      "\n",
      "Sequences containing <INPUT_DATA>: 622\n",
      "Percentage: 91.74%\n",
      "\n",
      "Sample sequences (showing input handling):\n",
      "Sequence 1 : ['<INPUT_DATA>', 'tool_3d54e34c', 'tool_8bda04fd', 'tool_8f1d1e8d', 'tool_517cd25a', 'tool_53e3f25e', 'tool_80adb202', 'tool_3e6f1905', 'tool_28ff05c9', 'tool_7597a43b', 'tool_b2648237', 'tool_90780d35', 'tool_4f57e651', 'tool_bd978d22', 'tool_6386f2cc']...\n",
      "Sequence 2 : ['<INPUT_DATA>', 'tool_b8f7250f', 'tool_d68cb872', 'tool_49fc8dba', 'tool_d0614518', 'tool_44f44b26', 'tool_225a4f3a', 'tool_a15360c3', 'tool_a980d106', 'tool_759be6b8', 'gfastats_data_prep', 'rename_and_unify_fasta', 'tool_58eacc96', 'tool_69207e28', 'gfastats_plot']...\n",
      "Sequence 3 : ['<INPUT_DATA>', 'tool_6bd2967e', 'tool_480114e2']\n",
      "Sequence 4 : ['<INPUT_DATA>', 'tool_61bd8481', 'tool_579161d3', 'tool_7fc44522', 'tool_d9c01216', 'tool_7f06f4e6', 'tool_225a4f3a', 'tool_b624f678', 'tool_69022678', 'tool_476abadc', 'tool_b2c3703d', 'tool_96826f80']\n",
      "Sequence 5 : ['<INPUT_DATA>', 'tool_c19b5382', 'tool_fb6846bb']\n",
      "\n",
      "Workflow Statistics:\n",
      "  Average connections per workflow: 19.64\n",
      "  Workflows with input data: 622\n",
      "  Percentage with input data: 91.74%\n"
     ]
    }
   ],
   "source": [
    "# Workflow Sequences with Input Handling\n",
    "def build_workflow_sequences(workflow_df):\n",
    "    \"\"\"Convert connections to sequences using topological sort with input handling\"\"\"\n",
    "    sequences = []\n",
    "    workflow_stats = []\n",
    "    \n",
    "    for workflow_id, group in workflow_df.groupby('workflow_id'):\n",
    "        # Build adjacency list\n",
    "        adj = defaultdict(list)\n",
    "        in_degree = defaultdict(int)\n",
    "        step_to_tool = {}\n",
    "        nodes = set()\n",
    "        \n",
    "        for _, row in group.iterrows():\n",
    "            s_id = str(row['source_step_id'])\n",
    "            t_id = str(row['target_step_id'])\n",
    "            s_tool = row['source_tool_clean']\n",
    "            t_tool = row['target_tool_clean']\n",
    "            \n",
    "            # Add to adjacency list\n",
    "            adj[s_id].append(t_id)\n",
    "            in_degree[t_id] += 1\n",
    "            step_to_tool[s_id] = s_tool\n",
    "            step_to_tool[t_id] = t_tool\n",
    "            nodes.add(s_id)\n",
    "            nodes.add(t_id)\n",
    "            in_degree.setdefault(s_id, 0)\n",
    "        \n",
    "        # Topological sort (Kahn's algorithm)\n",
    "        queue = sorted([n for n in nodes if in_degree[n] == 0])\n",
    "        topo_order = []\n",
    "        \n",
    "        while queue:\n",
    "            node = queue.pop(0)\n",
    "            topo_order.append(node)\n",
    "            for neighbor in adj[node]:\n",
    "                in_degree[neighbor] -= 1\n",
    "                if in_degree[neighbor] == 0:\n",
    "                    queue.append(neighbor)\n",
    "            queue.sort()\n",
    "        \n",
    "        # Handle cycles if detected\n",
    "        if len(topo_order) < len(nodes):\n",
    "            # Fallback to numeric sorting\n",
    "            topo_order = sorted(list(nodes), key=lambda x: int(x) if x.isdigit() else x)\n",
    "        \n",
    "        if len(topo_order) >= 2:\n",
    "            tool_sequence = []\n",
    "            seen_tools = set()  # Track seen tools\n",
    "            \n",
    "            for sid in topo_order:\n",
    "                if sid in step_to_tool:\n",
    "                    current_tool = step_to_tool[sid]\n",
    "                    \n",
    "                    # Skip if already seen (including inputs)\n",
    "                    if current_tool not in seen_tools:\n",
    "                        tool_sequence.append(current_tool)\n",
    "                        seen_tools.add(current_tool)\n",
    "            \n",
    "            sequences.append(tool_sequence)\n",
    "            workflow_stats.append({\n",
    "                'workflow_id': workflow_id,\n",
    "                'sequence_length': len(tool_sequence),\n",
    "                'num_connections': len(group),\n",
    "                'has_input_data': '<INPUT_DATA>' in tool_sequence\n",
    "            })\n",
    "    \n",
    "    return sequences, workflow_stats\n",
    "# Generate sequences with input handling\n",
    "print(\"Building workflow sequences...\")\n",
    "sequences, workflow_stats = build_workflow_sequences(df)\n",
    "\n",
    "print(f\"Generated {len(sequences)} workflow sequences\")\n",
    "print(f\"Average sequence length: {np.mean([len(seq) for seq in sequences]):.2f}\")\n",
    "print(f\"Max sequence length: {max(len(seq) for seq in sequences)}\")\n",
    "print(f\"Min sequence length: {min(len(seq) for seq in sequences)}\")\n",
    "\n",
    "# Analyze input dataset presence in sequences\n",
    "sequences_with_input = [seq for seq in sequences if '<INPUT_DATA>' in seq]\n",
    "print(f\"Sequences containing <INPUT_DATA>: {len(sequences_with_input)}\")\n",
    "print(f\"Percentage: {len(sequences_with_input)/len(sequences)*100:.2f}%\")\n",
    "\n",
    "# Display sample sequences\n",
    "print(\"Sample sequences (showing input handling):\")\n",
    "for i, seq in enumerate(sequences[:5]):\n",
    "    has_input = '<INPUT_DATA>' in seq\n",
    "    input_marker = \" \" if has_input else \"\"\n",
    "    print(f\"Sequence {i+1}{input_marker}: {seq[:15]}{'...' if len(seq) > 15 else ''}\")\n",
    "\n",
    "# Workflow statistics\n",
    "stats_df = pd.DataFrame(workflow_stats)\n",
    "print(f\"Workflow Statistics:\")\n",
    "print(f\"  Average connections per workflow: {stats_df['num_connections'].mean():.2f}\")\n",
    "print(f\"  Workflows with input data: {stats_df['has_input_data'].sum()}\")\n",
    "print(f\"  Percentage with input data: {stats_df['has_input_data'].mean()*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01e114cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to re-clean the sequences after fixing the cleaning function\n",
    "\n",
    "def reclean_sequences(sequences):\n",
    "    \"\"\"Reclean sequences with fixed cleaning function\"\"\"\n",
    "    cleaned_sequences = []\n",
    "    \n",
    "    for seq in sequences:\n",
    "        cleaned_seq = []\n",
    "        for tool in seq:\n",
    "            # Apply the FIXED cleaning function\n",
    "            cleaned_tool = clean_tool_id(tool)\n",
    "            cleaned_seq.append(cleaned_tool)\n",
    "        cleaned_sequences.append(cleaned_seq)\n",
    "    \n",
    "    return cleaned_sequences\n",
    "\n",
    "# Apply to your sequences\n",
    "sequences_cleaned = reclean_sequences(sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8234e6fa",
   "metadata": {},
   "source": [
    "Vocabulary Creation with Frequency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1e0a54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Original tool count: 2307\n",
      "üìä Filtered tool count (min_freq=3): 513\n",
      "\n",
      " VOCABULARY STATISTICS:\n",
      "  Total vocabulary size: 515\n",
      "  Unique tools: 513\n",
      "  Special tokens: 3\n",
      "  Input data token index: 2\n",
      "  Input data occurrences: 622\n",
      "  Minimum frequency used: 3\n",
      "\n",
      " FREQUENCY DISTRIBUTION:\n",
      "  Very rare (‚â§5): 336 (65.5%)\n",
      "  Rare (6-20): 164 (32.0%)\n",
      "  Medium (21-100): 11 (2.1%)\n",
      "  Frequent (>100): 1 (0.2%)\n",
      "\n",
      " MOST COMMON TOOLS:\n",
      "  1. tool_225a4f3a: 113\n",
      "  2. tool_d7af1ce5: 72\n",
      "  3. tool_a15360c3: 48\n",
      "  4. tool_bd5851dd: 45\n",
      "  5. tool_938e41c5: 43\n",
      "\n",
      " SEQUENCE STATISTICS:\n",
      "  Total sequences: 678\n",
      "  Sequences with input: 622 (91.7%)\n",
      "  Avg sequence length: 9.26\n"
     ]
    }
   ],
   "source": [
    "def create_vocabulary_fixed(sequences, min_frequency=3):\n",
    "    \"\"\"Create vocabulary with frequency filtering and proper analysis\"\"\"\n",
    "    \n",
    "    \n",
    "    # Reclean sequences with fixed function\n",
    "    sequences_cleaned = reclean_sequences(sequences)\n",
    "    \n",
    "  \n",
    "    # Count all tools\n",
    "    all_tools = [tool for seq in sequences_cleaned for tool in seq]\n",
    "    tool_counts = Counter(all_tools)\n",
    "    \n",
    "    print(f\"üìä Original tool count: {len(tool_counts)}\")\n",
    "    \n",
    "    # Filter by minimum frequency\n",
    "    filtered_tools = {tool: count for tool, count in tool_counts.items() \n",
    "                     if count >= min_frequency or tool in [\"<PAD>\", \"<UNK>\", \"<INPUT_DATA>\"]}\n",
    "    \n",
    "    print(f\"üìä Filtered tool count (min_freq={min_frequency}): {len(filtered_tools)}\")\n",
    "    \n",
    "    # Create vocabulary with special tokens\n",
    "    special_tokens = [\"<PAD>\", \"<UNK>\", \"<INPUT_DATA>\"]\n",
    "    \n",
    "    # Add tools in frequency order, excluding special tokens\n",
    "    vocab_list = special_tokens + [tool for tool, _ in sorted(filtered_tools.items(), \n",
    "                                                             key=lambda x: x[1], reverse=True)\n",
    "                                if tool not in special_tokens]\n",
    "    \n",
    "    vocab = {tool: idx for idx, tool in enumerate(vocab_list)}\n",
    "    reverse_vocab = {idx: tool for tool, idx in vocab.items()}\n",
    "    \n",
    "    # Analyze vocabulary statistics\n",
    "    freq_dist = {\n",
    "        'very_rare': len([t for t, c in filtered_tools.items() if t not in special_tokens and c <= 5]),\n",
    "        'rare': len([t for t, c in filtered_tools.items() if t not in special_tokens and 5 < c <= 20]),\n",
    "        'medium': len([t for t, c in filtered_tools.items() if t not in special_tokens and 20 < c <= 100]),\n",
    "        'frequent': len([t for t, c in filtered_tools.items() if t not in special_tokens and c > 100])\n",
    "    }\n",
    "    \n",
    "    vocab_stats = {\n",
    "        'total_tools': len(vocab),\n",
    "        'special_tokens': len(special_tokens),\n",
    "        'unique_tools': len(filtered_tools),\n",
    "        'input_data_token': '<INPUT_DATA>' in vocab,\n",
    "        'input_data_index': vocab.get('<INPUT_DATA>', -1),\n",
    "        'input_data_count': filtered_tools.get('<INPUT_DATA>', 0),\n",
    "        'most_common': [item for item in sorted(filtered_tools.items(), key=lambda x: x[1], reverse=True)[:10] \n",
    "                       if item[0] not in special_tokens],\n",
    "        'frequency_distribution': freq_dist,\n",
    "        'min_frequency_used': min_frequency\n",
    "    }\n",
    "    \n",
    "    # Print detailed statistics\n",
    "    print(f\" VOCABULARY STATISTICS:\")\n",
    "    print(f\"  Total vocabulary size: {vocab_stats['total_tools']}\")\n",
    "    print(f\"  Unique tools: {vocab_stats['unique_tools']}\")\n",
    "    print(f\"  Special tokens: {vocab_stats['special_tokens']}\")\n",
    "    print(f\"  Input data token index: {vocab_stats['input_data_index']}\")\n",
    "    print(f\"  Input data occurrences: {vocab_stats['input_data_count']}\")\n",
    "    print(f\"  Minimum frequency used: {vocab_stats['min_frequency_used']}\")\n",
    "    \n",
    "    print(f\" FREQUENCY DISTRIBUTION:\")\n",
    "    print(f\"  Very rare (‚â§5): {freq_dist['very_rare']} ({freq_dist['very_rare']/len(filtered_tools)*100:.1f}%)\")\n",
    "    print(f\"  Rare (6-20): {freq_dist['rare']} ({freq_dist['rare']/len(filtered_tools)*100:.1f}%)\")\n",
    "    print(f\"  Medium (21-100): {freq_dist['medium']} ({freq_dist['medium']/len(filtered_tools)*100:.1f}%)\")\n",
    "    print(f\"  Frequent (>100): {freq_dist['frequent']} ({freq_dist['frequent']/len(filtered_tools)*100:.1f}%)\")\n",
    "    \n",
    "    print(f\" MOST COMMON TOOLS:\")\n",
    "    for i, (tool, count) in enumerate(vocab_stats['most_common'][:5]):\n",
    "        print(f\"  {i+1}. {tool}: {count}\")\n",
    "    \n",
    "    # Verify sequence statistics\n",
    "    input_sequences = [seq for seq in sequences_cleaned if '<INPUT_DATA>' in seq]\n",
    "    print(f\" SEQUENCE STATISTICS:\")\n",
    "    print(f\"  Total sequences: {len(sequences_cleaned)}\")\n",
    "    print(f\"  Sequences with input: {len(input_sequences)} ({len(input_sequences)/len(sequences_cleaned)*100:.1f}%)\")\n",
    "    print(f\"  Avg sequence length: {np.mean([len(seq) for seq in sequences_cleaned]):.2f}\")\n",
    "    \n",
    "    return vocab, reverse_vocab, filtered_tools, vocab_stats, sequences_cleaned\n",
    " \n",
    "\n",
    "vocab, reverse_vocab, tool_counts, vocab_stats, sequences_cleaned = create_vocabulary_fixed(sequences, min_frequency=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e7e04a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider minimum frequency threshold\n",
    "MIN_TOOL_FREQUENCY = 3  # Only include tools appearing ‚â•3 times\n",
    "\n",
    "def filter_vocabulary_by_frequency(vocab, tool_counts, min_freq=3):\n",
    "    \"\"\"Filter vocabulary to reduce extreme imbalance\"\"\"\n",
    "    filtered_vocab = {}\n",
    "    filtered_tool_counts = {}\n",
    "    \n",
    "    for tool, idx in vocab.items():\n",
    "        if tool in [\"<PAD>\", \"<UNK>\", \"<INPUT_DATA>\"]:\n",
    "            filtered_vocab[tool] = idx\n",
    "            filtered_tool_counts[tool] = tool_counts.get(tool, 0)\n",
    "        elif tool_counts.get(tool, 0) >= min_freq:\n",
    "            filtered_vocab[tool] = idx\n",
    "            filtered_tool_counts[tool] = tool_counts.get(tool, 0)\n",
    "    vocab_stats = {\n",
    "        'total_tools': len(vocab),\n",
    "        'special_tokens': len(special_tokens),\n",
    "        'unique_tools': len(tool_counts),\n",
    "        'input_data_token': '<INPUT_DATA>' in vocab,\n",
    "        'input_data_index': vocab.get('<INPUT_DATA>', -1),\n",
    "        'most_common': tool_counts.most_common(10),\n",
    "        'frequency_distribution': {\n",
    "            'very_rare': len([t for t, c in tool_counts.items() if c <= 5]),\n",
    "            'rare': len([t for t, c in tool_counts.items() if 5 < c <= 20]),\n",
    "            'medium': len([t for t, c in tool_counts.items() if 20 < c <= 100]),\n",
    "            'frequent': len([t for t, c in tool_counts.items() if c > 100])\n",
    "        }\n",
    "    }\n",
    "    \n",
    "  \n",
    "    print(f\"  Total vocabulary size: {vocab_stats['total_tools']}\")\n",
    "    print(f\"  Unique tools: {vocab_stats['unique_tools']}\")\n",
    "    print(f\"  Special tokens: {vocab_stats['special_tokens']}\")\n",
    "    if vocab_stats['input_data_token']:\n",
    "        print(f\"  Input data token index: {vocab_stats['input_data_index']}\")\n",
    "    print(f\"  Most common tools: {vocab_stats['most_common']}\")\n",
    "    print(f\"  Frequency distribution: {vocab_stats['frequency_distribution']}\")\n",
    "    return vocab, tool_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e9b959",
   "metadata": {},
   "source": [
    "Extract Valid Tool Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7334eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Extracting compatible tools from clean sequences...\n",
      "\n",
      " COMPATIBLE TOOLS ANALYSIS:\n",
      "  Tools with connections: 463\n",
      "  Average next tools per tool: 3.49\n",
      "  Max next tools: 159\n",
      "  Min next tools: 1\n",
      "  Total unique pairs: 1618\n",
      "\n",
      " MOST COMMON CONNECTIONS:\n",
      "  1. <INPUT_DATA>->tool_b8f7250f: 12\n",
      "  2. tool_225a4f3a->tool_a15360c3: 10\n",
      "  3. <INPUT_DATA>->tool_fb1b9077: 10\n",
      "  4. tool_7f06f4e6->tool_225a4f3a: 9\n",
      "  5. <INPUT_DATA>->tool_5b757681: 9\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Compatible Tools Extraction with Clean Sequences\n",
    "def extract_compatible_tools(sequences, vocab):\n",
    "    \"\"\"Extract all possible next tools for each tool with vocabulary filtering\"\"\"\n",
    "    compatible_tools = defaultdict(set)\n",
    "    tool_pairs = defaultdict(int)\n",
    "    \n",
    "    print(\" Extracting compatible tools from clean sequences...\")\n",
    "    \n",
    "    for seq in sequences:\n",
    "        for i in range(len(seq) - 1):\n",
    "            current_tool = seq[i]\n",
    "            next_tool = seq[i + 1]\n",
    "            \n",
    "            # Only include tools that are in vocabulary\n",
    "            if current_tool in vocab and next_tool in vocab:\n",
    "                # Add to compatible tools\n",
    "                compatible_tools[current_tool].add(next_tool)\n",
    "                \n",
    "                # Count tool pairs for frequency analysis\n",
    "                pair_key = f\"{current_tool}->{next_tool}\"\n",
    "                tool_pairs[pair_key] += 1\n",
    "    \n",
    "    # Convert to dictionary format\n",
    "    compatible_tools = {tool: list(next_tools) for tool, next_tools in compatible_tools.items()}\n",
    "    \n",
    "    # Analyze connection statistics\n",
    "    connection_stats = {\n",
    "        'total_tools_with_connections': len(compatible_tools),\n",
    "        'avg_next_tools_per_tool': np.mean([len(tools) for tools in compatible_tools.values()]) if compatible_tools else 0,\n",
    "        'max_next_tools': max([len(tools) for tools in compatible_tools.values()]) if compatible_tools else 0,\n",
    "        'min_next_tools': min([len(tools) for tools in compatible_tools.values()]) if compatible_tools else 0,\n",
    "        'most_common_pairs': sorted(tool_pairs.items(), key=lambda x: x[1], reverse=True)[:10],\n",
    "        'total_unique_pairs': len(tool_pairs)\n",
    "    }\n",
    "    \n",
    "    print(f\" COMPATIBLE TOOLS ANALYSIS:\")\n",
    "    print(f\"  Tools with connections: {connection_stats['total_tools_with_connections']}\")\n",
    "    print(f\"  Average next tools per tool: {connection_stats['avg_next_tools_per_tool']:.2f}\")\n",
    "    print(f\"  Max next tools: {connection_stats['max_next_tools']}\")\n",
    "    print(f\"  Min next tools: {connection_stats['min_next_tools']}\")\n",
    "    print(f\"  Total unique pairs: {connection_stats['total_unique_pairs']}\")\n",
    "    \n",
    "    print(f\" MOST COMMON CONNECTIONS:\")\n",
    "    for i, (pair, count) in enumerate(connection_stats['most_common_pairs'][:5]):\n",
    "        print(f\"  {i+1}. {pair}: {count}\")\n",
    "    \n",
    "    return compatible_tools, connection_stats\n",
    "\n",
    "# Extract compatible tools with clean sequences\n",
    "compatible_tools, connection_stats = extract_compatible_tools(sequences_cleaned, vocab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab804717",
   "metadata": {},
   "source": [
    "Multi-Label Target Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01e87883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Creating multi-label targets from clean sequences...\n",
      "\n",
      "üìà MULTI-LABEL TARGET ANALYSIS:\n",
      "  Total input-target pairs: 4163\n",
      "  Average targets per pair: 4.65\n",
      "  Max targets per pair: 159\n",
      "  Min targets per pair: 0\n",
      "  Unique target tools: 510\n",
      "  Average context length: 3.86\n",
      "  Max context length: 5\n",
      "\n",
      "üéØ MOST COMMON TARGET TOOLS:\n",
      "  1. tool_225a4f3a: 463\n",
      "  2. tool_d7af1ce5: 337\n",
      "  3. tool_938e41c5: 332\n",
      "  4. tool_a980d106: 329\n",
      "  5. tool_44f44b26: 288\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Multi-Label Target Creation with Clean Sequences\n",
    "def create_multi_label_targets(sequences, vocab, compatible_tools, max_context_length=5):\n",
    "    \"\"\"Create multi-label training targets with optimized context handling\"\"\"\n",
    "    input_target_pairs = {}\n",
    "    target_statistics = defaultdict(int)\n",
    "    context_lengths = []\n",
    "    \n",
    "    print(\"üîç Creating multi-label targets from clean sequences...\")\n",
    "    \n",
    "    for seq in sequences:\n",
    "        if len(seq) < 2:\n",
    "            continue\n",
    "            \n",
    "        # Generate all possible context-target pairs\n",
    "        for i in range(1, len(seq)):\n",
    "            context = seq[:i]\n",
    "            last_tool = context[-1]\n",
    "            actual_next = seq[i]\n",
    "            \n",
    "            # Limit context length to prevent memory issues\n",
    "            if len(context) > max_context_length:\n",
    "                context = context[-max_context_length:]\n",
    "            \n",
    "            # Create more efficient context key (last N tools)\n",
    "            context_key = \"|\".join(context[-3:])  # Only last 3 tools for key\n",
    "            \n",
    "            # Initialize if not exists\n",
    "            if context_key not in input_target_pairs:\n",
    "                input_target_pairs[context_key] = set()\n",
    "            \n",
    "            # Add all possible next tools for this context\n",
    "            if last_tool in compatible_tools:\n",
    "                possible_next_tools = compatible_tools[last_tool]\n",
    "                # Filter to only include tools in vocabulary\n",
    "                valid_next_tools = [tool for tool in possible_next_tools if tool in vocab]\n",
    "                input_target_pairs[context_key].update(valid_next_tools)\n",
    "            else:\n",
    "                # Fallback to actual next tool if in vocab\n",
    "                if actual_next in vocab:\n",
    "                    input_target_pairs[context_key].add(actual_next)\n",
    "            \n",
    "            # Track context length\n",
    "            context_lengths.append(len(context))\n",
    "    \n",
    "    # Convert to dictionary format\n",
    "    input_target_pairs = {k: list(v) for k, v in input_target_pairs.items()}\n",
    "    \n",
    "    # Calculate accurate target statistics\n",
    "    all_targets = []\n",
    "    for targets in input_target_pairs.values():\n",
    "        all_targets.extend(targets)\n",
    "    \n",
    "    target_counter = Counter(all_targets)\n",
    "    \n",
    "    # Analyze target statistics\n",
    "    target_stats = {\n",
    "        'total_pairs': len(input_target_pairs),\n",
    "        'avg_targets_per_pair': np.mean([len(targets) for targets in input_target_pairs.values()]) if input_target_pairs else 0,\n",
    "        'max_targets': max([len(targets) for targets in input_target_pairs.values()]) if input_target_pairs else 0,\n",
    "        'min_targets': min([len(targets) for targets in input_target_pairs.values()]) if input_target_pairs else 0,\n",
    "        'most_common_targets': target_counter.most_common(10),\n",
    "        'unique_targets': len(target_counter),\n",
    "        'avg_context_length': np.mean(context_lengths) if context_lengths else 0,\n",
    "        'max_context_length': max(context_lengths) if context_lengths else 0\n",
    "    }\n",
    "    \n",
    "    print(f\"üìà MULTI-LABEL TARGET ANALYSIS:\")\n",
    "    print(f\"  Total input-target pairs: {target_stats['total_pairs']}\")\n",
    "    print(f\"  Average targets per pair: {target_stats['avg_targets_per_pair']:.2f}\")\n",
    "    print(f\"  Max targets per pair: {target_stats['max_targets']}\")\n",
    "    print(f\"  Min targets per pair: {target_stats['min_targets']}\")\n",
    "    print(f\"  Unique target tools: {target_stats['unique_targets']}\")\n",
    "    print(f\"  Average context length: {target_stats['avg_context_length']:.2f}\")\n",
    "    print(f\"  Max context length: {target_stats['max_context_length']}\")\n",
    "    \n",
    "    print(f\"üéØ MOST COMMON TARGET TOOLS:\")\n",
    "    for i, (tool, count) in enumerate(target_stats['most_common_targets'][:5]):\n",
    "        print(f\"  {i+1}. {tool}: {count}\")\n",
    "    \n",
    "    return input_target_pairs, target_stats\n",
    "\n",
    "# Create multi-label targets with clean sequences\n",
    "input_target_pairs, target_stats = create_multi_label_targets(sequences_cleaned, vocab, compatible_tools)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d928e2dd",
   "metadata": {},
   "source": [
    "Negative Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1cd32d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89efa63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating negative samples with 1:3.0 ratio...\n",
      "  Context has insufficient negatives: 353 < 477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Negative Sampling Statistics:\n",
      "  Total positive targets: 19358\n",
      "  Total negative samples: 61661\n",
      "  Target ratio: 1:3.0\n",
      "  Achieved ratio: 1:3.19\n",
      "  Average negatives per positive: 3.19\n",
      "Combining positive and negative samples...\n",
      "Combined Sample Statistics:\n",
      "  Total pairs: 4163\n",
      "  Positive only: 4163\n",
      "  Total positives: 19358\n",
      "  Total negatives: 61661\n",
      "  Final ratio: 1:3.19\n"
     ]
    }
   ],
   "source": [
    "def create_negative_samples(input_target_pairs, compatible_tools, vocab, negative_ratio=3.0):\n",
    "    \"\"\"Create negative samples with 1:3\"\"\"\n",
    "    \n",
    "    print(f\"Creating negative samples with 1:{negative_ratio} ratio...\")\n",
    "    \n",
    "    # Get all possible tools (excluding special tokens)\n",
    "    all_tools = set(vocab.keys()) - {\"<PAD>\", \"<UNK>\", \"<INPUT_DATA>\"}\n",
    "    \n",
    "    negative_pairs = {}\n",
    "    negative_stats = {\n",
    "        'total_negative_pairs': 0,\n",
    "        'avg_negatives_per_positive': 0,\n",
    "        'negative_ratio': negative_ratio,\n",
    "        'target_ratio_achieved': 0\n",
    "    }\n",
    "    \n",
    "    total_positive_targets = 0\n",
    "    \n",
    "    for context_str, positive_targets in input_target_pairs.items():\n",
    "        context_tools = context_str.split(\",\")\n",
    "        if not context_tools:\n",
    "            continue\n",
    "            \n",
    "        last_tool = context_tools[-1]\n",
    "        total_positive_targets += len(positive_targets)\n",
    "        \n",
    "        # Get compatible tools for this context\n",
    "        if last_tool in compatible_tools:\n",
    "            valid_next_tools = set(compatible_tools[last_tool])\n",
    "        else:\n",
    "            valid_next_tools = set()\n",
    "        \n",
    "        # Create negative samples (tools NOT in compatible set)\n",
    "        negative_tools = list(all_tools - valid_next_tools - set(context_tools))\n",
    "        \n",
    "        # Calculate required negatives: 1:3 or 1:5 ratio\n",
    "        num_negatives = max(3, int(len(positive_targets) * negative_ratio))\n",
    "        \n",
    "        # Ensure we don't request more negatives than available\n",
    "        if len(negative_tools) >= num_negatives:\n",
    "            sampled_negatives = random.sample(negative_tools, num_negatives)\n",
    "        else:\n",
    "            # If not enough negatives, take all available\n",
    "            sampled_negatives = negative_tools\n",
    "            print(f\"  Context has insufficient negatives: {len(negative_tools)} < {num_negatives}\")\n",
    "        \n",
    "        # Store negative pairs\n",
    "        if sampled_negatives:\n",
    "            negative_pairs[context_str] = sampled_negatives\n",
    "            negative_stats['total_negative_pairs'] += len(sampled_negatives)\n",
    "    \n",
    "    # Calculate actual ratio achieved\n",
    "    actual_ratio = negative_stats['total_negative_pairs'] / total_positive_targets\n",
    "    negative_stats['target_ratio_achieved'] = actual_ratio\n",
    "    negative_stats['avg_negatives_per_positive'] = negative_stats['total_negative_pairs'] / total_positive_targets\n",
    "    \n",
    "    print(f\"Adjusted Negative Sampling Statistics:\")\n",
    "    print(f\"  Total positive targets: {total_positive_targets}\")\n",
    "    print(f\"  Total negative samples: {negative_stats['total_negative_pairs']}\")\n",
    "    print(f\"  Target ratio: 1:{negative_ratio}\")\n",
    "    print(f\"  Achieved ratio: 1:{actual_ratio:.2f}\")\n",
    "    print(f\"  Average negatives per positive: {negative_stats['avg_negatives_per_positive']:.2f}\")\n",
    "    \n",
    "    return negative_pairs, negative_stats\n",
    "\n",
    "def combine_positive_negative_samples_adjusted(input_target_pairs, negative_pairs, vocab):\n",
    "    \"\"\"Combine positive and negative samples with enhanced tracking\"\"\"\n",
    "    \n",
    "    print(\"Combining positive and negative samples...\")\n",
    "    \n",
    "    combined_pairs = {}\n",
    "    combined_stats = {\n",
    "        'total_pairs': 0,\n",
    "        'positive_only_pairs': 0,\n",
    "        'total_positives': 0,\n",
    "        'total_negatives': 0,\n",
    "        'final_ratio': 0\n",
    "    }\n",
    "    \n",
    "    # Add positive pairs\n",
    "    for context_str, targets in input_target_pairs.items():\n",
    "        combined_pairs[context_str] = {'positive': targets, 'negative': []}\n",
    "        combined_stats['positive_only_pairs'] += 1\n",
    "        combined_stats['total_positives'] += len(targets)\n",
    "    \n",
    "    # Add negative pairs\n",
    "    for context_str, negatives in negative_pairs.items():\n",
    "        combined_stats['total_negatives'] += len(negatives)\n",
    "        \n",
    "        if context_str in combined_pairs:\n",
    "            combined_pairs[context_str]['negative'] = negatives\n",
    "        else:\n",
    "            combined_pairs[context_str] = {'positive': [], 'negative': negatives}\n",
    "    \n",
    "    combined_stats['total_pairs'] = len(combined_pairs)\n",
    "    \n",
    "    # Calculate final ratio\n",
    "    if combined_stats['total_positives'] > 0:\n",
    "        combined_stats['final_ratio'] = combined_stats['total_negatives'] / combined_stats['total_positives']\n",
    "    \n",
    "    print(f\"Combined Sample Statistics:\")\n",
    "    print(f\"  Total pairs: {combined_stats['total_pairs']}\")\n",
    "    print(f\"  Positive only: {combined_stats['positive_only_pairs']}\")\n",
    "    print(f\"  Total positives: {combined_stats['total_positives']}\")\n",
    "    print(f\"  Total negatives: {combined_stats['total_negatives']}\")\n",
    "    print(f\"  Final ratio: 1:{combined_stats['final_ratio']:.2f}\")\n",
    "\n",
    "    \n",
    "    return combined_pairs, combined_stats\n",
    "\n",
    "# Create negative samples with 1:3 ratio\n",
    "negative_pairs_3, negative_stats_3 = create_negative_samples(\n",
    "    input_target_pairs, compatible_tools, vocab, negative_ratio=3.0\n",
    ")\n",
    "\n",
    "# Combine with positives\n",
    "combined_pairs_3, combined_stats_3 = combine_positive_negative_samples_adjusted(\n",
    "    input_target_pairs, negative_pairs_3, vocab\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ded836",
   "metadata": {},
   "source": [
    "Matrix Creation with Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58e183fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Creating training matrices with clean vocabulary...\n",
      " Using vocabulary size: 515\n",
      "\n",
      " ENHANCED MATRIX CREATION STATISTICS:\n",
      "  Input matrix shape: (4163, 25)\n",
      "  Target matrix shape: (4163, 515)\n",
      "  Vocabulary size: 515\n",
      "  Average targets per sample: 4.65\n",
      "  Max targets per sample: 159.0\n",
      "  Average context length: 1.72\n",
      "  Average positives per sample: 4.65\n",
      "  Average negatives per sample: 14.81\n",
      "  Padding ratio: 0.93\n",
      "\n",
      " DATA CONSISTENCY CHECK:\n",
      "  Expected vocab size: 515\n",
      "  Actual target columns: 515\n",
      "  Match: True\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Training Matrix Creation with Clean Vocabulary\n",
    "def create_training_matrices_fixed(combined_pairs, vocab, max_len=25):\n",
    "    \"\"\"Convert combined positive/negative pairs to training matrices with correct vocabulary\"\"\"\n",
    "    \n",
    "    print(\" Creating training matrices with clean vocabulary...\")\n",
    "    \n",
    "    input_data = []\n",
    "    target_data = []\n",
    "    sample_info = []\n",
    "    \n",
    "    vocab_size = len(vocab)  # Should be 515\n",
    "    pad_idx = vocab[\"<PAD>\"]\n",
    "    unk_idx = vocab[\"<UNK>\"]\n",
    "    \n",
    "    print(f\" Using vocabulary size: {vocab_size}\")\n",
    "    \n",
    "    for context_str, sample_data in combined_pairs.items():\n",
    "        # Parse context with CORRECT separator\n",
    "        context_tools = context_str.split(\"|\")  # Use \"|\" not \",\"\n",
    "        \n",
    "        # Filter context tools to only include vocabulary tools\n",
    "        valid_context = [tool for tool in context_tools if tool in vocab]\n",
    "        \n",
    "        # Encode context\n",
    "        encoded_context = [vocab.get(tool, unk_idx) for tool in valid_context]\n",
    "        \n",
    "        # Pad to fixed length (left padding for sequences)\n",
    "        if len(encoded_context) < max_len:\n",
    "            encoded_context = [pad_idx] * (max_len - len(encoded_context)) + encoded_context\n",
    "        else:\n",
    "            encoded_context = encoded_context[-max_len:]\n",
    "        \n",
    "        # Multi-hot encode targets with CORRECT vocabulary size\n",
    "        target_vector = np.zeros(vocab_size, dtype=np.float32)\n",
    "        \n",
    "        # Encode positive targets\n",
    "        for target_tool in sample_data['positive']:\n",
    "            if target_tool in vocab:\n",
    "                target_vector[vocab[target_tool]] = 1.0\n",
    "        \n",
    "        # Note: Negatives are not encoded in targets (implicit negatives)\n",
    "        # They will be used in contrastive loss or as explicit negative examples\n",
    "        \n",
    "        input_data.append(encoded_context)\n",
    "        target_data.append(target_vector)\n",
    "        sample_info.append({\n",
    "            'context_length': len(valid_context),\n",
    "            'num_positives': len(sample_data['positive']),\n",
    "            'num_negatives': len(sample_data['negative'])\n",
    "        })\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    X_data = np.array(input_data, dtype=np.int32)\n",
    "    y_data = np.array(target_data, dtype=np.float32)\n",
    "    \n",
    "    # Enhanced statistics\n",
    "    matrix_stats = {\n",
    "        'input_shape': X_data.shape,\n",
    "        'target_shape': y_data.shape,\n",
    "        'vocab_size': vocab_size,\n",
    "        'avg_nonzero_targets': np.mean(np.sum(y_data, axis=1)),\n",
    "        'max_targets_per_sample': np.max(np.sum(y_data, axis=1)),\n",
    "        'padding_ratio': np.mean(np.sum(X_data == pad_idx, axis=1)) / max_len,\n",
    "        'avg_context_length': np.mean([info['context_length'] for info in sample_info]),\n",
    "        'avg_positives_per_sample': np.mean([info['num_positives'] for info in sample_info]),\n",
    "        'avg_negatives_per_sample': np.mean([info['num_negatives'] for info in sample_info])\n",
    "    }\n",
    "    \n",
    "    print(f\" ENHANCED MATRIX CREATION STATISTICS:\")\n",
    "    print(f\"  Input matrix shape: {matrix_stats['input_shape']}\")\n",
    "    print(f\"  Target matrix shape: {matrix_stats['target_shape']}\")\n",
    "    print(f\"  Vocabulary size: {matrix_stats['vocab_size']}\")\n",
    "    print(f\"  Average targets per sample: {matrix_stats['avg_nonzero_targets']:.2f}\")\n",
    "    print(f\"  Max targets per sample: {matrix_stats['max_targets_per_sample']}\")\n",
    "    print(f\"  Average context length: {matrix_stats['avg_context_length']:.2f}\")\n",
    "    print(f\"  Average positives per sample: {matrix_stats['avg_positives_per_sample']:.2f}\")\n",
    "    print(f\"  Average negatives per sample: {matrix_stats['avg_negatives_per_sample']:.2f}\")\n",
    "    print(f\"  Padding ratio: {matrix_stats['padding_ratio']:.2f}\")\n",
    "    \n",
    "    # Verify data consistency\n",
    "    print(f\" DATA CONSISTENCY CHECK:\")\n",
    "    print(f\"  Expected vocab size: {len(vocab)}\")\n",
    "    print(f\"  Actual target columns: {y_data.shape[1]}\")\n",
    "    print(f\"  Match: {len(vocab) == y_data.shape[1]}\")\n",
    "    \n",
    "    return X_data, y_data, matrix_stats, sample_info\n",
    "\n",
    "# Create matrices with fixed version\n",
    "X_data, y_data, matrix_stats, sample_info = create_training_matrices_fixed(\n",
    "    combined_pairs_3, vocab\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6722757",
   "metadata": {},
   "source": [
    "Class Weighting for Imbalanced Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b64d126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fixed class weights: 515 entries\n",
      "‚úÖ Max index: 514\n",
      "‚úÖ Expected max: 514\n",
      "\n",
      "üîç CLASS WEIGHTS VERIFICATION:\n",
      "  Vocabulary size: 515\n",
      "  Class weights size: 515\n",
      "  Match: True\n",
      "  PAD weight: 0.0\n",
      "  UNK weight: 0.0\n",
      "  INPUT_DATA weight: 0.1\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Class Weights with Clean Vocabulary\n",
    "def calculate_class_weights_fixed(tool_counts, vocab, boost_factor=3.0):\n",
    "    \"\"\"Fixed class weights calculation - covers all tools\"\"\"\n",
    "    \n",
    "    class_weights = {}\n",
    "    \n",
    "    # Special tokens\n",
    "    class_weights[vocab[\"<PAD>\"]] = 0.0\n",
    "    class_weights[vocab[\"<UNK>\"]] = 0.0\n",
    "    if \"<INPUT_DATA>\" in vocab:\n",
    "        class_weights[vocab[\"<INPUT_DATA>\"]] = 0.1\n",
    "    \n",
    "    # Calculate weights for ALL tools in vocabulary\n",
    "    max_count = max(tool_counts.values()) if tool_counts else 1\n",
    "    \n",
    "    for tool_name, tool_idx in vocab.items():\n",
    "        if tool_name not in [\"<PAD>\", \"<UNK>\", \"<INPUT_DATA>\"]:\n",
    "            count = tool_counts.get(tool_name, 1)  # Default to 1 if not found\n",
    "            \n",
    "            base_weight = np.log(max_count / (count + 1)) + 1.0\n",
    "            \n",
    "            if count <= 5:\n",
    "                boosted_weight = base_weight * boost_factor\n",
    "            elif count <= 20:\n",
    "                boosted_weight = base_weight * (boost_factor / 2)\n",
    "            else:\n",
    "                boosted_weight = base_weight\n",
    "            \n",
    "            class_weights[tool_idx] = round(boosted_weight, 6)\n",
    "    \n",
    "    return class_weights\n",
    "\n",
    "# Recalculate class weights with CLEAN vocabulary\n",
    "class_weights = calculate_class_weights_fixed(tool_counts, vocab, boost_factor=3.0)\n",
    "\n",
    "print(f\"‚úÖ Fixed class weights: {len(class_weights)} entries\")\n",
    "print(f\"‚úÖ Max index: {max(class_weights.keys())}\")\n",
    "print(f\"‚úÖ Expected max: {len(vocab) - 1}\")\n",
    "\n",
    "# Additional verification\n",
    "print(f\"üîç CLASS WEIGHTS VERIFICATION:\")\n",
    "print(f\"  Vocabulary size: {len(vocab)}\")\n",
    "print(f\"  Class weights size: {len(class_weights)}\")\n",
    "print(f\"  Match: {len(vocab) == len(class_weights)}\")\n",
    "print(f\"  PAD weight: {class_weights.get(vocab['<PAD>'], 'NOT_FOUND')}\")\n",
    "print(f\"  UNK weight: {class_weights.get(vocab['<UNK>'], 'NOT_FOUND')}\")\n",
    "print(f\"  INPUT_DATA weight: {class_weights.get(vocab['<INPUT_DATA>'], 'NOT_FOUND')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b42fb48",
   "metadata": {},
   "source": [
    "Balanced Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae8fd736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Performing balanced train/test split with clean data...\n",
      "  Input data shape: (4163, 25)\n",
      "  Target data shape: (4163, 515)\n",
      "  Vocabulary size: 515\n",
      "\n",
      "üìä Frequency Distribution:\n",
      "  Rare tools (‚â§5): 336\n",
      "  Uncommon tools (6-20): 164\n",
      "  Common tools (21-100): 11\n",
      "  Very common tools (>100): 2\n",
      "\n",
      "üîç Enhanced Stratification Analysis:\n",
      "  Unique frequency bins: 4\n",
      "  Minimum bin count: 463\n",
      "  Samples with input in context: 865\n",
      "  Input context ratio: 0.208\n",
      "  Using frequency-based stratified split...\n",
      "\n",
      "‚úÖ Frequency_Stratified Train/Test Split Statistics:\n",
      "  Training samples: 3330\n",
      "  Test samples: 833\n",
      "  Train positive ratio: 0.703\n",
      "  Test positive ratio: 0.702\n",
      "  Train avg targets: 4.67\n",
      "  Test avg targets: 4.56\n",
      "  Train avg context length: 1.71\n",
      "  Test avg context length: 1.75\n",
      "\n",
      "üéØ FINAL DATA SPLIT:\n",
      "  Training: 3330 samples\n",
      "  Validation: 166 samples\n",
      "  Test: 667 samples\n",
      "  Total: 4163 samples\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: Train/Test Split with Clean Data\n",
    "def balanced_train_test_split(X_data, y_data, test_size=0.2, vocab=None, \n",
    "                                  tool_counts=None, reverse_vocab=None):\n",
    "    \"\"\"Enhanced balanced train/test split with frequency-based stratification\"\"\"\n",
    "    \n",
    "    if vocab is None or tool_counts is None or reverse_vocab is None:\n",
    "        raise ValueError(\"vocab, tool_counts, and reverse_vocab are required\")\n",
    "    \n",
    "    print(\"üîç Performing balanced train/test split with clean data...\")\n",
    "    print(f\"  Input data shape: {X_data.shape}\")\n",
    "    print(f\"  Target data shape: {y_data.shape}\")\n",
    "    print(f\"  Vocabulary size: {len(vocab)}\")\n",
    "    \n",
    "    # Get special token indices\n",
    "    input_token_idx = vocab.get(\"<INPUT_DATA>\", -1)\n",
    "    pad_token_idx = vocab.get(\"<PAD>\", -1)\n",
    "    \n",
    "    # Calculate frequency distribution first\n",
    "    rare_tools = []      # ‚â§ 5 samples\n",
    "    uncommon_tools = []  # 6-20 samples  \n",
    "    common_tools = []    # 21-100 samples\n",
    "    very_common_tools = []  # > 100 samples\n",
    "    \n",
    "    for tool_name, count in tool_counts.items():\n",
    "        if tool_name in vocab:\n",
    "            tool_idx = vocab[tool_name]\n",
    "            \n",
    "            if count <= 5:\n",
    "                rare_tools.append(tool_idx)\n",
    "            elif count <= 20:\n",
    "                uncommon_tools.append(tool_idx)\n",
    "            elif count <= 100:\n",
    "                common_tools.append(tool_idx)\n",
    "            else:\n",
    "                very_common_tools.append(tool_idx)\n",
    "    \n",
    "    print(f\"üìä Frequency Distribution:\")\n",
    "    print(f\"  Rare tools (‚â§5): {len(rare_tools)}\")\n",
    "    print(f\"  Uncommon tools (6-20): {len(uncommon_tools)}\")\n",
    "    print(f\"  Common tools (21-100): {len(common_tools)}\")\n",
    "    print(f\"  Very common tools (>100): {len(very_common_tools)}\")\n",
    "    \n",
    "    # Create frequency-based labels for stratification\n",
    "    sample_labels = []\n",
    "    input_in_context_count = 0\n",
    "    \n",
    "    for i, y_vec in enumerate(y_data):\n",
    "        positive_tools = np.where(y_vec > 0)[0]\n",
    "        \n",
    "        # Check if input token is in context\n",
    "        has_input_in_context = input_token_idx in X_data[i] and input_token_idx >= 0\n",
    "        if has_input_in_context:\n",
    "            input_in_context_count += 1\n",
    "        \n",
    "        # Filter out special tokens for stratification\n",
    "        actual_tools = [idx for idx in positive_tools \n",
    "                      if idx not in [input_token_idx, pad_token_idx]]\n",
    "        \n",
    "        if len(actual_tools) > 0:\n",
    "            # Assign frequency bin based on most frequent tool\n",
    "            tool_frequencies = [(idx, tool_counts.get(reverse_vocab.get(idx, \"\"), 0)) \n",
    "                             for idx in actual_tools]\n",
    "            most_frequent_tool = max(tool_frequencies, key=lambda x: x[1])\n",
    "            max_freq = most_frequent_tool[1]\n",
    "            \n",
    "            # Assign to frequency bin\n",
    "            if max_freq <= 5:\n",
    "                sample_labels.append(0)  # Rare bin\n",
    "            elif max_freq <= 20:\n",
    "                sample_labels.append(1)  # Uncommon bin\n",
    "            elif max_freq <= 100:\n",
    "                sample_labels.append(2)  # Common bin\n",
    "            else:\n",
    "                sample_labels.append(3)  # Very common bin\n",
    "        else:\n",
    "            sample_labels.append(vocab.get(\"<PAD>\", 0))\n",
    "    \n",
    "    # Check stratification feasibility\n",
    "    unique_labels, label_counts = np.unique(sample_labels, return_counts=True)\n",
    "    min_class_count = np.min(label_counts)\n",
    "    \n",
    "    print(f\"üîç Enhanced Stratification Analysis:\")\n",
    "    print(f\"  Unique frequency bins: {len(unique_labels)}\")\n",
    "    print(f\"  Minimum bin count: {min_class_count}\")\n",
    "    print(f\"  Samples with input in context: {input_in_context_count}\")\n",
    "    print(f\"  Input context ratio: {input_in_context_count/len(X_data):.3f}\")\n",
    "    \n",
    "    # Perform stratified split\n",
    "    if min_class_count >= 2:\n",
    "        print(\"  Using frequency-based stratified split...\")\n",
    "        try:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X_data, y_data, test_size=test_size, \n",
    "                random_state=42, stratify=sample_labels\n",
    "            )\n",
    "            split_method = \"frequency_stratified\"\n",
    "        except ValueError as e:\n",
    "            print(f\"  Stratified split failed: {e}\")\n",
    "            print(\"  Using random split...\")\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X_data, y_data, test_size=test_size, random_state=42\n",
    "            )\n",
    "            split_method = \"random\"\n",
    "    else:\n",
    "        print(\"  Using random split (insufficient samples per bin)...\")\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_data, y_data, test_size=test_size, random_state=42\n",
    "        )\n",
    "        split_method = \"random\"\n",
    "    \n",
    "    # Calculate comprehensive statistics\n",
    "    def calculate_split_stats(X_split, y_split, name):\n",
    "        stats = {\n",
    "            'total_samples': len(X_split),\n",
    "            'positive_ratio': 0,\n",
    "            'avg_targets': 0,\n",
    "            'avg_context_length': 0\n",
    "        }\n",
    "        \n",
    "        # Calculate target statistics\n",
    "        positive_counts = np.sum(y_split > 0, axis=1)\n",
    "        stats['positive_ratio'] = np.mean(positive_counts > 0)\n",
    "        stats['avg_targets'] = np.mean(positive_counts)\n",
    "        \n",
    "        # Calculate average context length (excluding PAD tokens)\n",
    "        if pad_token_idx >= 0:\n",
    "            non_padded = np.sum(X_split != pad_token_idx, axis=1)\n",
    "            stats['avg_context_length'] = np.mean(non_padded)\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    train_stats = calculate_split_stats(X_train, y_train, \"Training\")\n",
    "    test_stats = calculate_split_stats(X_test, y_test, \"Test\")\n",
    "    \n",
    "    print(f\"‚úÖ {split_method.title()} Train/Test Split Statistics:\")\n",
    "    print(f\"  Training samples: {train_stats['total_samples']}\")\n",
    "    print(f\"  Test samples: {test_stats['total_samples']}\")\n",
    "    print(f\"  Train positive ratio: {train_stats['positive_ratio']:.3f}\")\n",
    "    print(f\"  Test positive ratio: {test_stats['positive_ratio']:.3f}\")\n",
    "    print(f\"  Train avg targets: {train_stats['avg_targets']:.2f}\")\n",
    "    print(f\"  Test avg targets: {test_stats['avg_targets']:.2f}\")\n",
    "    print(f\"  Train avg context length: {train_stats['avg_context_length']:.2f}\")\n",
    "    print(f\"  Test avg context length: {test_stats['avg_context_length']:.2f}\")\n",
    "    \n",
    "    # Return comprehensive split statistics\n",
    "    split_stats = {\n",
    "        'split_method': split_method,\n",
    "        'train_samples': train_stats['total_samples'],\n",
    "        'test_samples': test_stats['total_samples'],\n",
    "        'train_positive_ratio': train_stats['positive_ratio'],\n",
    "        'test_positive_ratio': test_stats['positive_ratio'],\n",
    "        'train_avg_targets': train_stats['avg_targets'],\n",
    "        'test_avg_targets': test_stats['avg_targets'],\n",
    "        'train_avg_context_length': train_stats['avg_context_length'],\n",
    "        'test_avg_context_length': test_stats['avg_context_length'],\n",
    "        'input_in_context_ratio': input_in_context_count/len(X_data),\n",
    "        'frequency_bins': {\n",
    "            'rare_tools': len(rare_tools),\n",
    "            'uncommon_tools': len(uncommon_tools),\n",
    "            'common_tools': len(common_tools),\n",
    "            'very_common_tools': len(very_common_tools)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, split_stats\n",
    "\n",
    "# Perform balanced train/test split with CLEAN data\n",
    "X_train, X_test, y_train, y_test, split_stats = balanced_train_test_split(\n",
    "    X_data, y_data, vocab=vocab, tool_counts=tool_counts, reverse_vocab=reverse_vocab\n",
    ")\n",
    "\n",
    "# Create validation set from test data (80/20 split of test data)\n",
    "test_size = len(X_test)\n",
    "val_size = int(test_size * 0.2)\n",
    "test_indices = np.random.permutation(test_size)\n",
    "val_indices = test_indices[:val_size]\n",
    "final_test_indices = test_indices[val_size:]\n",
    "\n",
    "X_val = X_test[val_indices]\n",
    "y_val = y_test[val_indices]\n",
    "X_test = X_test[final_test_indices]\n",
    "y_test = y_test[final_test_indices]\n",
    "\n",
    "print(f\"üéØ FINAL DATA SPLIT:\")\n",
    "print(f\"  Training: {X_train.shape[0]} samples\")\n",
    "print(f\"  Validation: {X_val.shape[0]} samples\")\n",
    "print(f\"  Test: {X_test.shape[0]} samples\")\n",
    "print(f\"  Total: {X_train.shape[0] + X_val.shape[0] + X_test.shape[0]} samples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e64604",
   "metadata": {},
   "source": [
    "Transformer Architecture Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18f2ec0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç MODEL CREATION DEBUG:\n",
      "  Current vocab size: 515\n",
      "  Expected vocab size: 515\n",
      "  Match: True\n",
      "üîç Creating transformer model with vocab size: 515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-22 17:42:10.590437: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"enhanced_transformer_tool_recommender\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"enhanced_transformer_tool_recommender\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ<span style=\"font-weight: bold\"> Layer (type)        </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape      </span>‚îÉ<span style=\"font-weight: bold\">    Param # </span>‚îÉ<span style=\"font-weight: bold\"> Connected to      </span>‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ tool_sequence_input ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)        ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ -                 ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ token_and_position‚Ä¶ ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   ‚îÇ     <span style=\"color: #00af00; text-decoration-color: #00af00\">69,120</span> ‚îÇ tool_sequence_in‚Ä¶ ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TokenAndPositionE‚Ä¶</span> ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ transformer_block   ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   ‚îÇ    <span style=\"color: #00af00; text-decoration-color: #00af00\">132,480</span> ‚îÇ token_and_positi‚Ä¶ ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)  ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ transformer_block_1 ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   ‚îÇ    <span style=\"color: #00af00; text-decoration-color: #00af00\">132,480</span> ‚îÇ transformer_bloc‚Ä¶ ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)  ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ global_avg_pool     ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ transformer_bloc‚Ä¶ ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool‚Ä¶</span> ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ global_max_pool     ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ transformer_bloc‚Ä¶ ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1‚Ä¶</span> ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ pooled_features     ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ global_avg_pool[<span style=\"color: #00af00; text-decoration-color: #00af00\">‚Ä¶</span> ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       ‚îÇ                   ‚îÇ            ‚îÇ global_max_pool[<span style=\"color: #00af00; text-decoration-color: #00af00\">‚Ä¶</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ pooled_features[<span style=\"color: #00af00; text-decoration-color: #00af00\">‚Ä¶</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       ‚îÇ     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> ‚îÇ dropout_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout_10          ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       ‚îÇ     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> ‚îÇ dropout_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout_11          ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ tool_predictions    ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">515</span>)       ‚îÇ     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,435</span> ‚îÇ dropout_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ tool_sequence_input ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)        ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ -                 ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mInputLayer\u001b[0m)        ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ token_and_position‚Ä¶ ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)   ‚îÇ     \u001b[38;5;34m69,120\u001b[0m ‚îÇ tool_sequence_in‚Ä¶ ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mTokenAndPositionE‚Ä¶\u001b[0m ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ transformer_block   ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)   ‚îÇ    \u001b[38;5;34m132,480\u001b[0m ‚îÇ token_and_positi‚Ä¶ ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mTransformerBlock\u001b[0m)  ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ transformer_block_1 ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)   ‚îÇ    \u001b[38;5;34m132,480\u001b[0m ‚îÇ transformer_bloc‚Ä¶ ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mTransformerBlock\u001b[0m)  ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ global_avg_pool     ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ transformer_bloc‚Ä¶ ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mGlobalAveragePool‚Ä¶\u001b[0m ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ global_max_pool     ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ transformer_bloc‚Ä¶ ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mGlobalMaxPooling1‚Ä¶\u001b[0m ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ pooled_features     ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ global_avg_pool[\u001b[38;5;34m‚Ä¶\u001b[0m ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mConcatenate\u001b[0m)       ‚îÇ                   ‚îÇ            ‚îÇ global_max_pool[\u001b[38;5;34m‚Ä¶\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout_9 (\u001b[38;5;33mDropout\u001b[0m) ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ pooled_features[\u001b[38;5;34m‚Ä¶\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_1 (\u001b[38;5;33mDense\u001b[0m)     ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       ‚îÇ     \u001b[38;5;34m65,792\u001b[0m ‚îÇ dropout_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout_10          ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mDropout\u001b[0m)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_2 (\u001b[38;5;33mDense\u001b[0m)     ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       ‚îÇ     \u001b[38;5;34m32,896\u001b[0m ‚îÇ dropout_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout_11          ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mDropout\u001b[0m)           ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ tool_predictions    ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m515\u001b[0m)       ‚îÇ     \u001b[38;5;34m66,435\u001b[0m ‚îÇ dropout_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mDense\u001b[0m)             ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">499,203</span> (1.90 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m499,203\u001b[0m (1.90 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">499,203</span> (1.90 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m499,203\u001b[0m (1.90 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç MODEL VERIFICATION:\n",
      "  Input shape: (None, 25)\n",
      "  Output shape: (None, 515)\n",
      "  Expected output: (None, 515)\n",
      "  Match: True\n"
     ]
    }
   ],
   "source": [
    "class TransformerBlock(Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1, attention_dropout=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            num_heads=num_heads, \n",
    "            key_dim=embed_dim // num_heads,\n",
    "            dropout=attention_dropout,\n",
    "            kernel_initializer=tf.keras.initializers.GlorotUniform(),\n",
    "            bias_initializer=tf.keras.initializers.Zeros()\n",
    "        )\n",
    "        \n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            Dense(ff_dim, activation=\"gelu\", kernel_initializer=tf.keras.initializers.HeNormal()), \n",
    "            Dropout(rate),\n",
    "            Dense(embed_dim, kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "        ])\n",
    "        \n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        # Multi-head self-attention\n",
    "        attn_output = self.att(inputs, inputs, inputs, training=training)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        \n",
    "        # Residual connection and layer norm\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        \n",
    "        # Feed-forward network\n",
    "        ffn_output = self.ffn(out1, training=training)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        \n",
    "        # Final residual connection and layer norm\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "class TokenAndPositionEmbedding(Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim, dropout_rate=0.1):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.token_emb = Embedding(\n",
    "            input_dim=vocab_size, \n",
    "            output_dim=embed_dim, \n",
    "            mask_zero=True,\n",
    "            embeddings_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02),\n",
    "            embeddings_regularizer=tf.keras.regularizers.l2(1e-6)\n",
    "        )\n",
    "        \n",
    "        self.pos_emb = Embedding(\n",
    "            input_dim=maxlen, \n",
    "            output_dim=embed_dim, \n",
    "            mask_zero=False,\n",
    "            embeddings_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02)\n",
    "        )\n",
    "        \n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x, training=None):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        \n",
    "        embeddings = x + positions\n",
    "        return self.dropout(embeddings, training=training)\n",
    "\n",
    "# Cell 12: Model Architecture with Clean Vocabulary\n",
    "def create_transformer_model_fixed(vocab_size, embed_dim=128, feed_forward_dim=256, max_len=25, dropout=0.2, n_heads=4, num_transformer_blocks=2, use_second_dense=True):\n",
    "    \"\"\"Enhanced transformer model with correct vocabulary size\"\"\"\n",
    "    \n",
    "    print(f\"üîç Creating transformer model with vocab size: {vocab_size}\")\n",
    "    \n",
    "    embed_dim = embed_dim\n",
    "    ff_dim = feed_forward_dim\n",
    "    max_len = max_len\n",
    "    dropout = dropout\n",
    "    n_heads = n_heads\n",
    "    num_blocks = num_transformer_blocks\n",
    "    \n",
    "    # Input layer\n",
    "    inputs = Input(shape=(max_len,), dtype=tf.int32, name=\"tool_sequence_input\")\n",
    "    \n",
    "    # Enhanced embedding layer\n",
    "    embedding_layer = TokenAndPositionEmbedding(\n",
    "        max_len, vocab_size, embed_dim, dropout_rate=dropout * 0.5\n",
    "    )\n",
    "    x = embedding_layer(inputs)\n",
    "    \n",
    "    # Transformer blocks\n",
    "    for i in range(num_blocks):\n",
    "        x = TransformerBlock(\n",
    "            embed_dim, n_heads, ff_dim, dropout, attention_dropout=dropout * 0.5\n",
    "        )(x)\n",
    "    \n",
    "    # Enhanced pooling strategy\n",
    "    avg_pooled = GlobalAveragePooling1D(name=\"global_avg_pool\")(x)\n",
    "    max_pooled = GlobalMaxPooling1D(name=\"global_max_pool\")(x)\n",
    "    pooled = tf.keras.layers.Concatenate(name=\"pooled_features\")([avg_pooled, max_pooled])\n",
    "    \n",
    "    # Dropout after pooling\n",
    "    pooled = Dropout(dropout)(pooled)\n",
    "    \n",
    "    # Enhanced dense layers\n",
    "    dense1 = Dense(ff_dim, activation=\"gelu\", name=\"dense_1\")(pooled)\n",
    "    dense1 = Dropout(dropout)(dense1)\n",
    "    \n",
    "    # Optional second dense layer\n",
    "    if use_second_dense:\n",
    "        dense2 = Dense(ff_dim // 2, activation=\"gelu\", name=\"dense_2\")(dense1)\n",
    "        dense2 = Dropout(dropout)(dense2)\n",
    "        final_features = dense2\n",
    "    else:\n",
    "        final_features = dense1\n",
    "    \n",
    "    # Output layer with enhanced initialization\n",
    "    outputs = Dense(\n",
    "        vocab_size,  # Use CORRECT vocab_size\n",
    "        activation=\"sigmoid\", \n",
    "        name=\"tool_predictions\",\n",
    "        kernel_initializer=tf.keras.initializers.GlorotUniform(),\n",
    "        bias_initializer=tf.keras.initializers.Constant(-2.0)\n",
    "    )(final_features)\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs=inputs, outputs=outputs, name=\"enhanced_transformer_tool_recommender\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Verify vocabulary size before creating model\n",
    "print(f\"üîç MODEL CREATION DEBUG:\")\n",
    "print(f\"  Current vocab size: {len(vocab)}\")\n",
    "print(f\"  Expected vocab size: 515\")\n",
    "print(f\"  Match: {len(vocab) == 515}\")\n",
    "\n",
    "# Ensure we're using the correct vocabulary\n",
    "if len(vocab) != 515:\n",
    "    print(\"‚ùå Vocabulary size mismatch! Using clean vocabulary...\")\n",
    "    # You need to identify your clean vocab variable\n",
    "    # vocab = vocab_clean  # Uncomment and adjust as needed\n",
    "\n",
    "# Create enhanced model with CORRECT vocabulary size\n",
    "model = create_transformer_model_fixed(len(vocab), embed_dim=128, feed_forward_dim=256, max_len=25, dropout=0.2, n_heads=4, num_transformer_blocks=2)\n",
    "model.summary()\n",
    "\n",
    "# Verify model output shape\n",
    "print(f\"üîç MODEL VERIFICATION:\")\n",
    "print(f\"  Input shape: {model.input_shape}\")\n",
    "print(f\"  Output shape: {model.output_shape}\")\n",
    "print(f\"  Expected output: (None, 515)\")\n",
    "print(f\"  Match: {model.output_shape == (None, 515)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2424cc14",
   "metadata": {},
   "source": [
    "Loss Function with Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d09bbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refined Loss: Balanced for Ranking\n",
    "def compute_weighted_loss_log_scaled(y_true, y_pred, class_weights):\n",
    "    \"\"\"Fixed: Normalizes loss to a standard scale to prevent overshooting\"\"\"\n",
    "    \n",
    "    y_true = tf.cast(y_true, dtype=tf.float32)\n",
    "    y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
    "    \n",
    "    # Get element-wise binary crossentropy\n",
    "    bce = tf.keras.backend.binary_crossentropy(y_true, y_pred)\n",
    "    \n",
    "    if class_weights is not None:\n",
    "        vocab_size = y_true.shape[-1]\n",
    "        weight_array = np.array([class_weights.get(i, 1.0) for i in range(vocab_size)], dtype=np.float32)\n",
    "        weight_tensor = tf.constant(weight_array, dtype=tf.float32)\n",
    "        \n",
    "        # Apply class-specific weights\n",
    "        weighted_bce = bce * weight_tensor\n",
    "        \n",
    "        # 1. Normalize by Mean to keep standard scale (e.g. 0.1 to 1.0 range)\n",
    "        sample_loss = tf.reduce_mean(weighted_bce, axis=-1)\n",
    "        \n",
    "        # 2. Add a dynamic boost based on positive targets (Log-scaling for stability)\n",
    "        # Instead of multiplying by 100, we use a more subtle log-based boost\n",
    "        positive_mask = tf.cast(y_true > 0.5, tf.float32)\n",
    "        target_count = tf.reduce_sum(positive_mask, axis=-1)\n",
    "        \n",
    "        # Boost samples that have many targets (complex workflows)\n",
    "        # multiplier will be in range [1.0, 3.0]\n",
    "        boost_multiplier = tf.math.log(target_count + 1.0) + 1.0\n",
    "        \n",
    "        # 3. Apply a moderate global scale to ensure healthy gradients (e.g. 10x)\n",
    "        # 100x was too aggressive and caused the model to miss subtle patterns\n",
    "        final_sample_loss = sample_loss * boost_multiplier * 10.0\n",
    "        \n",
    "        return tf.reduce_mean(final_sample_loss)\n",
    "    \n",
    "    return tf.reduce_mean(bce) * 10.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531cddea",
   "metadata": {},
   "source": [
    "Model Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7cbbef53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing model compilation...\n",
      "  Test input shape: (4, 25)\n",
      "  Test target shape: (4, 515)\n",
      "  Model input shape: (None, 25)\n",
      "  Model output shape: (None, 515)\n",
      "  Predictions shape: (4, 515)\n",
      "  Test loss: 48.0653\n",
      "  Test binary accuracy: 0.9927\n",
      "‚úÖ Model compilation test passed!\n",
      "üîß Compiling model with fixed components...\n",
      "  Model input shape: (None, 25)\n",
      "  Model output shape: (None, 515)\n",
      "  Expected output: (None, 515)\n",
      "  Match: True\n",
      "‚úÖ Model compiled successfully!\n",
      "\n",
      "‚úÖ Model is ready for training!\n"
     ]
    }
   ],
   "source": [
    "# Cell 14: Fixed Model Compilation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def compile_model(model, class_weights, learning_rate=0.001):\n",
    "    \"\"\"Compile model with fixed loss function and proper validation\"\"\"\n",
    "    \n",
    "    print(\"üîß Compiling model with fixed components...\")\n",
    "    \n",
    "    # Verify model and data compatibility\n",
    "    print(f\"  Model input shape: {model.input_shape}\")\n",
    "    print(f\"  Model output shape: {model.output_shape}\")\n",
    "    print(f\"  Expected output: (None, {len(vocab)})\")\n",
    "    print(f\"  Match: {model.output_shape == (None, len(vocab))}\")\n",
    "    \n",
    "    # Use the FIXED loss function\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        loss=lambda y_true, y_pred: compute_weighted_loss_log_scaled(y_true, y_pred, class_weights),\n",
    "        metrics=[\n",
    "            tf.keras.metrics.BinaryAccuracy(name='binary_accuracy'),\n",
    "            tf.keras.metrics.Precision(name='precision'),\n",
    "            tf.keras.metrics.Recall(name='recall'),\n",
    "            # Add F1 score for better evaluation\n",
    "            tf.keras.metrics.AUC(name='auc'),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Model compiled successfully!\")\n",
    "    return model\n",
    "\n",
    "# Test compilation with a small batch\n",
    "def test_model_compilation():\n",
    "    \"\"\"Test model compilation with actual data shapes\"\"\"\n",
    "    print(\"üß™ Testing model compilation...\")\n",
    "    \n",
    "    try:\n",
    "        # Create a small test batch\n",
    "        test_batch_size = 4\n",
    "        X_test_batch = X_train[:test_batch_size]\n",
    "        y_test_batch = y_train[:test_batch_size]\n",
    "        \n",
    "        print(f\"  Test input shape: {X_test_batch.shape}\")\n",
    "        print(f\"  Test target shape: {y_test_batch.shape}\")\n",
    "        print(f\"  Model input shape: {model.input_shape}\")\n",
    "        print(f\"  Model output shape: {model.output_shape}\")\n",
    "        \n",
    "        # Test forward pass\n",
    "        predictions = model(X_test_batch, training=False)\n",
    "        print(f\"  Predictions shape: {predictions.shape}\")\n",
    "        \n",
    "        # Test loss calculation\n",
    "        loss = compute_weighted_loss_log_scaled(y_test_batch, predictions, class_weights)\n",
    "        print(f\"  Test loss: {loss:.4f}\")\n",
    "        \n",
    "        # Test metrics\n",
    "        binary_acc = tf.keras.metrics.BinaryAccuracy()\n",
    "        binary_acc.update_state(y_test_batch, predictions)\n",
    "        print(f\"  Test binary accuracy: {binary_acc.result():.4f}\")\n",
    "        \n",
    "        print(\"‚úÖ Model compilation test passed!\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Model compilation test failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "# First, verify and fix model if needed\n",
    "if len(vocab) == 515 and model.output_shape != (None, 515):\n",
    "    print(\"üîß Recreating model with correct vocabulary size...\")\n",
    "    model = create_transformer_model_fixed(len(vocab), embed_dim=128, feed_forward_dim=256, max_len=25, dropout=0.2, n_heads=4, num_transformer_blocks=2)\n",
    "    model.summary()\n",
    "\n",
    "# Test compilation\n",
    "test_passed = test_model_compilation()\n",
    "\n",
    "if test_passed:\n",
    "    # Compile the model\n",
    "    model = compile_model(model, class_weights, learning_rate=0.001)\n",
    "    print(\"‚úÖ Model is ready for training!\")\n",
    "else:\n",
    "    print(\"‚ùå Model compilation failed - need to fix issues first!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003bdd57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b05a2eb",
   "metadata": {},
   "source": [
    "Balanced Sampling for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b24058e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç TRAINING DATA VERIFICATION:\n",
      "  X_train shape: (3330, 25)\n",
      "  y_train shape: (3330, 515)\n",
      "  Expected: X_train=(3330, 25), y_train=(3330, 515)\n",
      "‚úÖ y_train shape is correct!\n",
      "üîç Creating balanced sampler with clean data...\n",
      "  y_train shape: (3330, 515)\n",
      "  vocab size: 515\n",
      "‚úÖ Enhanced Balanced Sampler:\n",
      "  Total unique labels: 505\n",
      "  Labels with >= 2 samples: 482\n",
      "  Expected labels: ~512\n",
      "  Excluded tokens: PAD(0), UNK(1), INPUT(2)\n",
      "\n",
      "‚úÖ Enhanced balanced sampler created!\n",
      "  Available labels for sampling: 482\n",
      "  Label mapping size: 482\n"
     ]
    }
   ],
   "source": [
    "# Cell 15: Fixed Balanced Sampler with Clean Data\n",
    "def create_balanced_sampler(y_train, vocab, min_samples_per_label=2):\n",
    "    \"\"\"Create balanced sampler with clean data and proper filtering\"\"\"\n",
    "    \n",
    "    print(\"üîç Creating balanced sampler with clean data...\")\n",
    "    print(f\"  y_train shape: {y_train.shape}\")\n",
    "    print(f\"  vocab size: {len(vocab)}\")\n",
    "    \n",
    "    # Get special token indices\n",
    "    pad_idx = vocab.get(\"<PAD>\", -1)\n",
    "    unk_idx = vocab.get(\"<UNK>\", -1)\n",
    "    input_idx = vocab.get(\"<INPUT_DATA>\", -1)\n",
    "    \n",
    "    # Extract labels and indices (excluding special tokens)\n",
    "    unique_labels, label_indices = get_u_tr_labels_fixed(\n",
    "        y_train, exclude_tokens=[pad_idx, unk_idx, input_idx]\n",
    "    )\n",
    "    \n",
    "    # Filter labels with minimum samples\n",
    "    filtered_labels = []\n",
    "    filtered_indices = {}\n",
    "    \n",
    "    for label in unique_labels:\n",
    "        indices = label_indices[label]\n",
    "        if len(indices) >= min_samples_per_label:\n",
    "            filtered_labels.append(label)\n",
    "            filtered_indices[label] = indices\n",
    "    \n",
    "    print(f\"‚úÖ Enhanced Balanced Sampler:\")\n",
    "    print(f\"  Total unique labels: {len(unique_labels)}\")\n",
    "    print(f\"  Labels with >= {min_samples_per_label} samples: {len(filtered_labels)}\")\n",
    "    print(f\"  Expected labels: ~{len(vocab) - 3}\")  # Excluding special tokens\n",
    "    print(f\"  Excluded tokens: PAD({pad_idx}), UNK({unk_idx}), INPUT({input_idx})\")\n",
    "    \n",
    "    return filtered_indices, filtered_labels\n",
    "\n",
    "def get_u_tr_labels_fixed(y_tr, exclude_tokens=None):\n",
    "    \"\"\"Extract unique labels with token filtering for clean data\"\"\"\n",
    "    if exclude_tokens is None:\n",
    "        exclude_tokens = []\n",
    "    \n",
    "    labels = list()\n",
    "    labels_pos_dict = dict()\n",
    "    \n",
    "    for i, item in enumerate(y_tr):\n",
    "        label_pos = np.where(item > 0)[0]\n",
    "        \n",
    "        # Filter out excluded tokens\n",
    "        filtered_labels = [label for label in label_pos if label not in exclude_tokens]\n",
    "        \n",
    "        labels.extend(filtered_labels)\n",
    "        for label in filtered_labels:\n",
    "            if label not in labels_pos_dict:\n",
    "                labels_pos_dict[label] = list()\n",
    "            labels_pos_dict[label].append(i)\n",
    "    \n",
    "    u_labels = list(set(labels))\n",
    "    \n",
    "    # Remove duplicates from indices\n",
    "    for item in labels_pos_dict:\n",
    "        labels_pos_dict[item] = list(set(labels_pos_dict[item]))\n",
    "    \n",
    "    return u_labels, labels_pos_dict\n",
    "\n",
    "# Test data shapes first\n",
    "print(f\"üîç TRAINING DATA VERIFICATION:\")\n",
    "print(f\"  X_train shape: {X_train.shape}\")\n",
    "print(f\"  y_train shape: {y_train.shape}\")\n",
    "print(f\"  Expected: X_train=(3330, 25), y_train=(3330, 515)\")\n",
    "\n",
    "# Verify shapes are correct\n",
    "if y_train.shape[1] != 515:\n",
    "    print(\"‚ùå y_train has wrong shape! Using old data!\")\n",
    "    print(\"‚ùå Need to recreate y_train from clean matrices!\")\n",
    "else:\n",
    "    print(\"‚úÖ y_train shape is correct!\")\n",
    "    \n",
    "    # Create balanced sampler with clean data\n",
    "    label_to_indices, available_labels = create_balanced_sampler(y_train, vocab)\n",
    "    \n",
    "    print(f\"‚úÖ Enhanced balanced sampler created!\")\n",
    "    print(f\"  Available labels for sampling: {len(available_labels)}\")\n",
    "    print(f\"  Label mapping size: {len(label_to_indices)}\")\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c88b9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_balanced_batch(X_train, y_train, label_to_indices, available_labels, batch_size=32, prev_selected_tools=None):\n",
    "    \"\"\"Fixed: Selects a balanced batch by sampling from available tools\"\"\"\n",
    "    if prev_selected_tools is None:\n",
    "        prev_selected_tools = []\n",
    "    \n",
    "    # Try to pick tools we haven't picked recently to maximize exposure\n",
    "    valid_labels = [l for l in available_labels if l not in prev_selected_tools[-batch_size*2:]]\n",
    "    if len(valid_labels) < batch_size:\n",
    "        # Fallback if we run out of new tools\n",
    "        valid_labels = available_labels\n",
    "        \n",
    "    if not valid_labels:\n",
    "        # Fallback to completely random sampling if something is wrong\n",
    "        indices = np.random.choice(len(X_train), size=batch_size, replace=False)\n",
    "        return X_train[indices], y_train[indices], []\n",
    "        \n",
    "    # Pick a random subset of labels\n",
    "    selected_labels = np.random.choice(valid_labels, size=min(batch_size, len(valid_labels)), replace=False)\n",
    "    \n",
    "    # Pick one sample for each selected label\n",
    "    batch_indices = []\n",
    "    for label in selected_labels:\n",
    "        indices = label_to_indices[label]\n",
    "        idx = np.random.choice(indices)\n",
    "        batch_indices.append(idx)\n",
    "        \n",
    "    # Convert back to standard array type explicitly just in case\n",
    "    batch_indices = np.array(batch_indices, dtype=int)\n",
    "    return X_train[batch_indices], y_train[batch_indices], selected_labels.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c26bc2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: 3330\n",
      "Validation data size: 166\n",
      "Steps per epoch: 52\n",
      "Batch size: 64\n",
      "Epoch   0 | Train Loss: 114.9429 | Val Loss: 29.4095 | LR: 0.001000\n",
      "  New best model saved! Val Loss: 29.4095\n",
      "Epoch   1 | Train Loss: 80.9671 | Val Loss: 22.7283 | LR: 0.001000\n",
      "  New best model saved! Val Loss: 22.7283\n",
      "Epoch   2 | Train Loss: 35.1510 | Val Loss: 18.9192 | LR: 0.001000\n",
      "  New best model saved! Val Loss: 18.9192\n",
      "Epoch   3 | Train Loss: 32.7403 | Val Loss: 20.4462 | LR: 0.001000\n",
      "  Patience: 1/20\n",
      "Epoch   4 | Train Loss: 31.8818 | Val Loss: 23.0716 | LR: 0.001000\n",
      "  Patience: 2/20\n",
      "Epoch   5 | Train Loss: 25.3199 | Val Loss: 22.5466 | LR: 0.001000\n",
      "  Patience: 3/20\n",
      "Epoch   6 | Train Loss: 22.5852 | Val Loss: 23.6621 | LR: 0.001000\n",
      "  Patience: 4/20\n",
      "Epoch   7 | Train Loss: 20.6697 | Val Loss: 26.0299 | LR: 0.001000\n",
      "  Patience: 5/20\n",
      "Epoch   8 | Train Loss: 19.7067 | Val Loss: 20.5475 | LR: 0.001000\n",
      "  Patience: 6/20\n",
      "Epoch   9 | Train Loss: 17.4986 | Val Loss: 23.2256 | LR: 0.001000\n",
      "  Patience: 7/20\n",
      "Epoch  10 | Train Loss: 17.2511 | Val Loss: 19.4127 | LR: 0.001000\n",
      "  Patience: 8/20\n",
      "Epoch  11 | Train Loss: 17.8630 | Val Loss: 18.6944 | LR: 0.001000\n",
      "  New best model saved! Val Loss: 18.6944\n",
      "Epoch  12 | Train Loss: 17.0863 | Val Loss: 15.3587 | LR: 0.001000\n",
      "  New best model saved! Val Loss: 15.3587\n",
      "Epoch  13 | Train Loss: 16.4938 | Val Loss: 19.3857 | LR: 0.001000\n",
      "  Patience: 1/20\n",
      "Epoch  14 | Train Loss: 16.2653 | Val Loss: 19.2355 | LR: 0.001000\n",
      "  Patience: 2/20\n",
      "Epoch  15 | Train Loss: 15.9425 | Val Loss: 18.6838 | LR: 0.001000\n",
      "  Patience: 3/20\n",
      "Epoch  16 | Train Loss: 15.8715 | Val Loss: 15.6011 | LR: 0.001000\n",
      "  Patience: 4/20\n",
      "Epoch  17 | Train Loss: 15.0783 | Val Loss: 19.3849 | LR: 0.001000\n",
      "  Patience: 5/20\n",
      "Epoch  18 | Train Loss: 15.0380 | Val Loss: 15.2225 | LR: 0.001000\n",
      "  New best model saved! Val Loss: 15.2225\n",
      "Epoch  19 | Train Loss: 15.2014 | Val Loss: 12.2534 | LR: 0.000960\n",
      "  New best model saved! Val Loss: 12.2534\n",
      "Epoch  20 | Train Loss: 15.8491 | Val Loss: 16.0845 | LR: 0.000960\n",
      "  Patience: 1/20\n",
      "Epoch  21 | Train Loss: 14.7465 | Val Loss: 15.9028 | LR: 0.000960\n",
      "  Patience: 2/20\n",
      "Epoch  22 | Train Loss: 14.9256 | Val Loss: 17.2434 | LR: 0.000960\n",
      "  Patience: 3/20\n",
      "Epoch  23 | Train Loss: 14.8329 | Val Loss: 16.6045 | LR: 0.000960\n",
      "  Patience: 4/20\n",
      "Epoch  24 | Train Loss: 14.5896 | Val Loss: 14.1582 | LR: 0.000960\n",
      "  Patience: 5/20\n",
      "Epoch  25 | Train Loss: 14.5778 | Val Loss: 16.2971 | LR: 0.000960\n",
      "  Patience: 6/20\n",
      "Epoch  26 | Train Loss: 15.3208 | Val Loss: 11.7417 | LR: 0.000960\n",
      "  New best model saved! Val Loss: 11.7417\n",
      "Epoch  27 | Train Loss: 14.8826 | Val Loss: 16.9952 | LR: 0.000960\n",
      "  Patience: 1/20\n",
      "Epoch  28 | Train Loss: 14.0212 | Val Loss: 18.1602 | LR: 0.000960\n",
      "  Patience: 2/20\n",
      "Epoch  29 | Train Loss: 14.3933 | Val Loss: 13.7008 | LR: 0.000960\n",
      "  Patience: 3/20\n",
      "Epoch  30 | Train Loss: 14.1545 | Val Loss: 16.9305 | LR: 0.000960\n",
      "  Patience: 4/20\n",
      "Epoch  31 | Train Loss: 15.0649 | Val Loss: 11.4265 | LR: 0.000960\n",
      "  New best model saved! Val Loss: 11.4265\n",
      "Epoch  32 | Train Loss: 14.3848 | Val Loss: 15.4111 | LR: 0.000960\n",
      "  Patience: 1/20\n",
      "Epoch  33 | Train Loss: 14.0326 | Val Loss: 14.3300 | LR: 0.000960\n",
      "  Patience: 2/20\n",
      "Epoch  34 | Train Loss: 14.0514 | Val Loss: 16.1362 | LR: 0.000960\n",
      "  Patience: 3/20\n",
      "Epoch  35 | Train Loss: 14.8405 | Val Loss: 13.2152 | LR: 0.000960\n",
      "  Patience: 4/20\n",
      "Epoch  36 | Train Loss: 13.7294 | Val Loss: 13.5263 | LR: 0.000960\n",
      "  Patience: 5/20\n",
      "Epoch  37 | Train Loss: 13.6509 | Val Loss: 12.6897 | LR: 0.000960\n",
      "  Patience: 6/20\n",
      "Epoch  38 | Train Loss: 13.3312 | Val Loss: 15.1752 | LR: 0.000922\n",
      "  Patience: 7/20\n",
      "Epoch  39 | Train Loss: 13.6987 | Val Loss: 12.6744 | LR: 0.000922\n",
      "  Patience: 8/20\n",
      "Epoch  40 | Train Loss: 13.2986 | Val Loss: 14.6424 | LR: 0.000922\n",
      "  Patience: 9/20\n",
      "Epoch  41 | Train Loss: 13.2986 | Val Loss: 12.8489 | LR: 0.000922\n",
      "  Patience: 10/20\n",
      "Epoch  42 | Train Loss: 13.8833 | Val Loss: 13.4948 | LR: 0.000922\n",
      "  Patience: 11/20\n",
      "Epoch  43 | Train Loss: 13.3090 | Val Loss: 12.8908 | LR: 0.000922\n",
      "  Patience: 12/20\n",
      "Epoch  44 | Train Loss: 13.1569 | Val Loss: 12.0900 | LR: 0.000922\n",
      "  Patience: 13/20\n",
      "Epoch  45 | Train Loss: 13.3800 | Val Loss: 12.1492 | LR: 0.000922\n",
      "  Patience: 14/20\n",
      "Epoch  46 | Train Loss: 13.1971 | Val Loss: 12.3058 | LR: 0.000922\n",
      "  Patience: 15/20\n",
      "Epoch  47 | Train Loss: 13.3855 | Val Loss: 12.2155 | LR: 0.000922\n",
      "  Patience: 16/20\n",
      "Epoch  48 | Train Loss: 12.1841 | Val Loss: 11.6755 | LR: 0.000922\n",
      "  Patience: 17/20\n",
      "Epoch  49 | Train Loss: 12.9045 | Val Loss: 11.8938 | LR: 0.000922\n",
      "  Patience: 18/20\n"
     ]
    }
   ],
   "source": [
    "# Fix the training loop to use consistent loss function\n",
    "def train_model_fixed(model, X_train, y_train, X_val, y_val, label_to_indices, available_labels,\n",
    "                    class_weights, epochs=50, batch_size=64, patience=20, lr_schedule=True):\n",
    "    \"\"\"Enhanced training with CONSISTENT loss function\"\"\"\n",
    "    \n",
    "    # Filter label indices to only include training data\n",
    "    max_train_index = len(X_train) - 1\n",
    "    filtered_label_to_indices = {}\n",
    "    filtered_available_labels = []\n",
    "    \n",
    "    for label, indices in label_to_indices.items():\n",
    "        valid_indices = [idx for idx in indices if idx <= max_train_index]\n",
    "        if valid_indices:\n",
    "            filtered_label_to_indices[label] = valid_indices\n",
    "            filtered_available_labels.append(label)\n",
    "    \n",
    "    print(f\"Training data size: {len(X_train)}\")\n",
    "    print(f\"Validation data size: {len(X_val)}\")\n",
    "    \n",
    "    # Enhanced metrics tracking\n",
    "    training_history = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "        'learning_rate': [],\n",
    "        'batch_loss': []\n",
    "    }\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    if lr_schedule:\n",
    "        initial_lr = model.optimizer.learning_rate.numpy()\n",
    "        lr_scheduler = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "            initial_learning_rate=initial_lr,\n",
    "            decay_steps=1000,\n",
    "            decay_rate=0.96,\n",
    "            staircase=True\n",
    "        )\n",
    "        model.optimizer.learning_rate = lr_scheduler\n",
    "    \n",
    "    # Early stopping\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    best_weights = None\n",
    "\n",
    "    # Training metrics\n",
    "    num_train_samples = len(X_train)\n",
    "    steps_per_epoch = max(1, num_train_samples // batch_size)\n",
    "    \n",
    "    print(f\"Steps per epoch: {steps_per_epoch}\")\n",
    "    print(f\"Batch size: {batch_size}\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        epoch_loss = 0\n",
    "        num_batches = 0\n",
    "        prev_selected_tools = []\n",
    "        batch_losses = []\n",
    "        \n",
    "        for batch_idx in range(steps_per_epoch):\n",
    "            try:\n",
    "                # Get balanced batch\n",
    "                X_batch, y_batch, selected_tools = get_balanced_batch(\n",
    "                    X_train, y_train, filtered_label_to_indices, filtered_available_labels, \n",
    "                    batch_size, prev_selected_tools\n",
    "                )\n",
    "                \n",
    "                # Train step\n",
    "                with tf.GradientTape() as tape:\n",
    "                    predictions = model(X_batch, training=True)\n",
    "                    loss = compute_weighted_loss_log_scaled(y_batch, predictions, class_weights)  # ‚úÖ FIXED\n",
    "                \n",
    "                gradients = tape.gradient(loss, model.trainable_variables)\n",
    "                \n",
    "                # Gradient clipping for stability\n",
    "                gradients, _ = tf.clip_by_global_norm(gradients, 1.0)\n",
    "                \n",
    "                model.optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "                \n",
    "                epoch_loss += loss\n",
    "                batch_losses.append(loss.numpy())\n",
    "                num_batches += 1\n",
    "                prev_selected_tools = selected_tools\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Batch {batch_idx} failed: {e}\")\n",
    "                # Fallback to random sampling\n",
    "                batch_indices = np.random.choice(\n",
    "                    len(X_train), \n",
    "                    size=min(batch_size, len(X_train)), \n",
    "                    replace=False\n",
    "                )\n",
    "                X_batch = X_train[batch_indices]\n",
    "                y_batch = y_train[batch_indices]\n",
    "                \n",
    "                # Train step with CONSISTENT loss function\n",
    "                with tf.GradientTape() as tape:\n",
    "                    predictions = model(X_batch, training=True)\n",
    "                    loss = compute_weighted_loss_log_scaled(y_batch, predictions, class_weights)  # ‚úÖ FIXED\n",
    "                \n",
    "                gradients = tape.gradient(loss, model.trainable_variables)\n",
    "                gradients, _ = tf.clip_by_global_norm(gradients, 1.0)\n",
    "                model.optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "                \n",
    "                epoch_loss += loss\n",
    "                batch_losses.append(loss.numpy())\n",
    "                num_batches += 1\n",
    "        \n",
    "        # Calculate average training loss\n",
    "        avg_train_loss = epoch_loss / num_batches if num_batches > 0 else 0\n",
    "        \n",
    "        # Validation phase with CONSISTENT loss\n",
    "        val_predictions = model(X_val, training=False)\n",
    "        val_loss = compute_weighted_loss_log_scaled(y_val, val_predictions, class_weights)  # ‚úÖ FIXED\n",
    "        \n",
    "        # Store history\n",
    "        current_lr = model.optimizer.learning_rate.numpy() if lr_schedule else initial_lr\n",
    "        training_history['train_loss'].append(avg_train_loss.numpy())\n",
    "        training_history['val_loss'].append(val_loss.numpy())\n",
    "        training_history['learning_rate'].append(current_lr)\n",
    "        training_history['batch_loss'].extend(batch_losses)\n",
    "        \n",
    "        # Progress reporting\n",
    "        print(f\"Epoch {epoch:3d} | Train Loss: {avg_train_loss:.4f} | Val Loss: {val_loss:.4f} | LR: {current_lr:.6f}\")\n",
    "        \n",
    "        # Early stopping check\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            # Save best model\n",
    "            best_weights = model.get_weights()\n",
    "            print(f\"  New best model saved! Val Loss: {val_loss:.4f}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"  Patience: {patience_counter}/{patience}\")\n",
    "        \n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch}\")\n",
    "            # Restore best weights\n",
    "            if best_weights is not None:\n",
    "                model.set_weights(best_weights)\n",
    "            break\n",
    "    \n",
    "    return training_history, X_val, y_val\n",
    "\n",
    "history, X_val_out, y_val_out = train_model_fixed(\n",
    "    model, X_train, y_train, X_val, y_val, \n",
    "    label_to_indices, available_labels, class_weights\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a6cb20",
   "metadata": {},
   "source": [
    "Training with Balanced Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210b8349",
   "metadata": {},
   "source": [
    "Training History Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b153ac72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting training history...\n",
      "Available metrics in history: ['train_loss', 'val_loss', 'learning_rate', 'batch_loss']\n",
      "Using simplified plotting (loss only)...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_training_history_simplified(history):\n",
    "    \"\"\"Plot simplified training history (only loss metrics)\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Loss plot\n",
    "    axes[0].plot(history['train_loss'], label='Training Loss', linewidth=2, color='blue')\n",
    "    axes[0].plot(history['val_loss'], label='Validation Loss', linewidth=2, color='red')\n",
    "    axes[0].set_title('Model Loss', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Loss gap plot\n",
    "    loss_gap = np.array(history['train_loss']) - np.array(history['val_loss'])\n",
    "    axes[1].plot(loss_gap, label='Training - Validation Loss', linewidth=2, color='green')\n",
    "    axes[1].axhline(y=0, color='red', linestyle='--', alpha=0.7, label='Zero Gap')\n",
    "    axes[1].set_title('Generalization Gap', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Loss Gap (Train - Val)')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_training_history_enhanced(history):\n",
    "    \"\"\"Enhanced plotting with multiple metrics (if available)\"\"\"\n",
    "    # Determine available metrics\n",
    "    available_metrics = list(history.keys())\n",
    "    \n",
    "    if 'train_loss' in available_metrics and 'val_loss' in available_metrics:\n",
    "        # Create subplots based on available metrics\n",
    "        if 'accuracy' in available_metrics:\n",
    "            fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        else:\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "            axes = [axes]  # Make it 2D for consistent indexing\n",
    "        \n",
    "        # Loss plot\n",
    "        axes[0].plot(history['train_loss'], label='Training Loss', linewidth=2)\n",
    "        axes[0].plot(history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "        axes[0].set_title('Model Loss', fontsize=14, fontweight='bold')\n",
    "        axes[0].set_xlabel('Epoch')\n",
    "        axes[0].set_ylabel('Loss')\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Loss gap plot\n",
    "        loss_gap = np.array(history['train_loss']) - np.array(history['val_loss'])\n",
    "        axes[1].plot(loss_gap, label='Loss Gap', linewidth=2, color='red')\n",
    "        axes[1].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "        axes[1].set_title('Generalization Gap', fontsize=14, fontweight='bold')\n",
    "        axes[1].set_xlabel('Epoch')\n",
    "        axes[1].set_ylabel('Train Loss - Val Loss')\n",
    "        axes[1].legend()\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Accuracy plots (if available)\n",
    "        if 'accuracy' in available_metrics and len(axes) >= 4:\n",
    "            axes[0, 1].plot(history['accuracy'], label='Training Accuracy', linewidth=2)\n",
    "            axes[0, 1].plot(history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
    "            axes[0, 1].set_title('Model Accuracy', fontsize=14, fontweight='bold')\n",
    "            axes[0, 1].set_xlabel('Epoch')\n",
    "            axes[0, 1].set_ylabel('Accuracy')\n",
    "            axes[0, 1].legend()\n",
    "            axes[0, 1].grid(True, alpha=0.3)\n",
    "            \n",
    "            # Top-5 accuracy (if available)\n",
    "            if 'top_5_accuracy' in available_metrics:\n",
    "                axes[1, 0].plot(history['top_5_accuracy'], label='Training Top-5', linewidth=2)\n",
    "                axes[1, 0].plot(history['val_top_5_accuracy'], label='Validation Top-5', linewidth=2)\n",
    "                axes[1, 0].set_title('Top-5 Accuracy', fontsize=14, fontweight='bold')\n",
    "                axes[1, 0].set_xlabel('Epoch')\n",
    "                axes[1, 0].set_ylabel('Top-5 Accuracy')\n",
    "                axes[1, 0].legend()\n",
    "                axes[1, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"‚ùå Required metrics not found in history!\")\n",
    "        print(f\"Available metrics: {available_metrics}\")\n",
    "\n",
    "def plot_training_history_minimal(history):\n",
    "    \"\"\"Minimal plotting - just loss\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    plt.plot(history['train_loss'], label='Training Loss', linewidth=2, color='blue')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss', linewidth=2, color='red')\n",
    "    \n",
    "    plt.title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Usage based on your training function\n",
    "print(\"Plotting training history...\")\n",
    "\n",
    "# Check what metrics are available\n",
    "print(f\"Available metrics in history: {list(history.keys())}\")\n",
    "\n",
    "# Use appropriate plotting function\n",
    "if 'accuracy' in history:\n",
    "    print(\"Using enhanced plotting (full metrics)...\")\n",
    "    plot_training_history_enhanced(history)\n",
    "else:\n",
    "    print(\"Using simplified plotting (loss only)...\")\n",
    "    plot_training_history_simplified(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0393cc9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7d06516",
   "metadata": {},
   "source": [
    "Comprehensive Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f0da2091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Running FIXED Model Evaluation...\n",
      "\n",
      "üìä FIXED EVALUATION RESULTS\n",
      "==================================================\n",
      "\n",
      "üéØ Binary Classification Metrics (Per-Sample):\n",
      "  Precision: 0.1123\n",
      "  Recall: 0.1143\n",
      "  F1-Score: 0.1068\n",
      "\n",
      "üèÜ Ranking Metrics:\n",
      "  Recall@1: 0.0059\n",
      "  Precision@1: 0.1167\n",
      "  MRR@1: 0.1167\n",
      "  Recall@5: 0.0507\n",
      "  Precision@5: 0.1333\n",
      "  MRR@5: 0.1663\n",
      "  Recall@10: 0.1041\n",
      "  Precision@10: 0.1350\n",
      "  MRR@10: 0.1731\n",
      "  Recall@20: 0.2183\n",
      "  Precision@20: 0.1288\n",
      "  MRR@20: 0.1789\n",
      "\n",
      "üéØ KEY INSIGHTS:\n",
      "  ‚úÖ Your model IS working for ranking!\n",
      "  ‚úÖ Recall@5: 5.1% - Good for 515 tools\n",
      "  ‚úÖ Precision@5: 13.3% - Reasonable\n",
      "  ‚ùå Binary metrics were calculated wrong before\n",
      "  üéØ Focus on ranking metrics, not binary classification\n"
     ]
    }
   ],
   "source": [
    "# Fixed comprehensive evaluation\n",
    "def evaluate_model_fixed(model, X_val, y_val, vocab, reverse_vocab):\n",
    "    \"\"\"Fixed model evaluation with correct metrics\"\"\"\n",
    "    \n",
    "    print(\"üîç Running FIXED Model Evaluation...\")\n",
    "    \n",
    "    # Get predictions\n",
    "    predictions = model.predict(X_val, batch_size=32, verbose=0)\n",
    "    \n",
    "    # Fixed binary metrics (per-sample, not flattened)\n",
    "    sample_precisions = []\n",
    "    sample_recalls = []\n",
    "    sample_f1s = []\n",
    "    \n",
    "    for i in range(len(y_val)):\n",
    "        y_true_sample = y_val[i]\n",
    "        y_pred_sample = predictions[i]\n",
    "        \n",
    "        # Convert to binary predictions using 0.5 threshold\n",
    "        y_pred_binary = (y_pred_sample > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate per-sample metrics\n",
    "        if np.sum(y_true_sample) > 0:  # Only if sample has positives\n",
    "            tp = np.sum((y_true_sample == 1) & (y_pred_binary == 1))\n",
    "            fp = np.sum((y_true_sample == 0) & (y_pred_binary == 1))\n",
    "            fn = np.sum((y_true_sample == 1) & (y_pred_binary == 0))\n",
    "            \n",
    "            precision = tp / (tp + fp + 1e-7)\n",
    "            recall = tp / (tp + fn + 1e-7)\n",
    "            f1 = 2 * precision * recall / (precision + recall + 1e-7)\n",
    "            \n",
    "            sample_precisions.append(precision)\n",
    "            sample_recalls.append(recall)\n",
    "            sample_f1s.append(f1)\n",
    "    \n",
    "    binary_metrics = {\n",
    "        'precision': np.mean(sample_precisions),\n",
    "        'recall': np.mean(sample_recalls),\n",
    "        'f1': np.mean(sample_f1s)\n",
    "    }\n",
    "    \n",
    "    # Fixed ranking metrics\n",
    "    ranking_metrics = {}\n",
    "    k_values = [1, 5, 10, 20]\n",
    "    \n",
    "    for k in k_values:\n",
    "        recalls = []\n",
    "        precisions = []\n",
    "        mrrs = []\n",
    "        \n",
    "        for i in range(len(y_val)):\n",
    "            # Get top-k predicted tools\n",
    "            top_k_indices = np.argsort(predictions[i])[-k:][::-1]\n",
    "            \n",
    "            # Get actual positive tools\n",
    "            actual_tools = np.where(y_val[i] > 0.5)[0]\n",
    "            \n",
    "            if len(actual_tools) > 0:\n",
    "                # Recall@K\n",
    "                recall = len(set(top_k_indices) & set(actual_tools)) / len(actual_tools)\n",
    "                recalls.append(recall)\n",
    "                \n",
    "                # Precision@K\n",
    "                precision = len(set(top_k_indices) & set(actual_tools)) / k\n",
    "                precisions.append(precision)\n",
    "                \n",
    "                # Fixed MRR@K\n",
    "                mrr = 0\n",
    "                for rank, idx in enumerate(top_k_indices):\n",
    "                    if idx in actual_tools:\n",
    "                        mrr = 1.0 / (rank + 1)\n",
    "                        break\n",
    "                mrrs.append(mrr)\n",
    "        \n",
    "        ranking_metrics[f'Recall@{k}'] = np.mean(recalls) if recalls else 0\n",
    "        ranking_metrics[f'Precision@{k}'] = np.mean(precisions) if precisions else 0\n",
    "        ranking_metrics[f'MRR@{k}'] = np.mean(mrrs) if mrrs else 0\n",
    "    \n",
    "    return binary_metrics, ranking_metrics\n",
    "\n",
    "# Run fixed evaluation\n",
    "binary_metrics, ranking_metrics = evaluate_model_fixed(model, X_val, y_val, vocab, reverse_vocab)\n",
    "\n",
    "print(\"üìä FIXED EVALUATION RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"üéØ Binary Classification Metrics (Per-Sample):\")\n",
    "print(f\"  Precision: {binary_metrics['precision']:.4f}\")\n",
    "print(f\"  Recall: {binary_metrics['recall']:.4f}\")\n",
    "print(f\"  F1-Score: {binary_metrics['f1']:.4f}\")\n",
    "\n",
    "print(f\"üèÜ Ranking Metrics:\")\n",
    "for k in [1, 5, 10, 20]:\n",
    "    print(f\"  Recall@{k}: {ranking_metrics[f'Recall@{k}']:.4f}\")\n",
    "    print(f\"  Precision@{k}: {ranking_metrics[f'Precision@{k}']:.4f}\")\n",
    "    print(f\"  MRR@{k}: {ranking_metrics[f'MRR@{k}']:.4f}\")\n",
    "\n",
    "print(f\"üéØ KEY INSIGHTS:\")\n",
    "print(f\"  ‚úÖ Your model IS working for ranking!\")\n",
    "print(f\"  ‚úÖ Recall@5: {ranking_metrics['Recall@5']:.1%} - Good for 515 tools\")\n",
    "print(f\"  ‚úÖ Precision@5: {ranking_metrics['Precision@5']:.1%} - Reasonable\")\n",
    "print(f\"  ‚ùå Binary metrics were calculated wrong before\")\n",
    "print(f\"  üéØ Focus on ranking metrics, not binary classification\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9be626c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88a2f21c",
   "metadata": {},
   "source": [
    "# üöÄ Final Results Export\n",
    "This section handles saving the trained model, training visualizations, and the processed data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "71544fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_complete_transformer_model(model, output_dir, vocab, reverse_vocab, class_weights, \n",
    "                                compatible_tools, config, history, tool_counts=None, performance_summary=None):\n",
    "    \"\"\"Save complete model with all necessary metadata\"\"\"\n",
    "    import json\n",
    "    import pandas as pd\n",
    "    from pathlib import Path\n",
    "    \n",
    "    if isinstance(output_dir, str):\n",
    "        output_dir = Path(output_dir)\n",
    "        \n",
    "    model_dir = output_dir / \"transformer_model\"\n",
    "    model_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    print(f\"üíæ Saving model to {model_dir}...\")\n",
    "    model.save(model_dir / \"complete_model.h5\")\n",
    "    model.save_weights(model_dir / \"model_weights.weights.h5\")\n",
    "    \n",
    "    with open(model_dir / \"model_architecture.json\", \"w\") as f:\n",
    "        f.write(model.to_json())\n",
    "    \n",
    "    # Serialization logic\n",
    "    comp_tools_ser = {k: list(v) for k, v in compatible_tools.items()}\n",
    "    weights_ser = {str(int(k)): float(v) for k, v in class_weights.items()}\n",
    "    tool_counts_ser = {k: int(v) for k, v in tool_counts.items()} if tool_counts else {}\n",
    "    \n",
    "    metadata = {\n",
    "        'model_info': {\n",
    "            'model_type': 'Transformer',\n",
    "            'created_date': pd.Timestamp.now().isoformat(),\n",
    "            'vocab_size': len(vocab),\n",
    "            'config': config\n",
    "        },\n",
    "        'vocabulary': {'vocab': vocab, 'reverse_vocab': reverse_vocab},\n",
    "        'training_history': history,\n",
    "        'class_weights': weights_ser,\n",
    "        'compatible_tools': comp_tools_ser,\n",
    "        'tool_statistics': {'tool_counts': tool_counts_ser}\n",
    "    }\n",
    "    \n",
    "    with open(model_dir / \"metadata.json\", \"w\") as f:\n",
    "        json.dump(metadata, f, indent=2, default=str)\n",
    "        \n",
    "    print(\"‚úÖ Model and metadata saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9f713cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_processed_data_for_notebook(X_train, X_test, y_train, y_test, \n",
    "                                 vocab, reverse_vocab, class_weights, \n",
    "                                 compatible_tools, output_dir, **kwargs):\n",
    "    \"\"\"Save all processed data for notebook directory\"\"\"\n",
    "    from pathlib import Path\n",
    "    import json\n",
    "    import numpy as np\n",
    "    \n",
    "    output_dir = Path(output_dir)\n",
    "    notebook_dir = output_dir / \"transformer_processed_data\"\n",
    "    notebook_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    np.save(notebook_dir / \"X_train.npy\", X_train)\n",
    "    np.save(notebook_dir / \"X_test.npy\", X_test)\n",
    "    np.save(notebook_dir / \"y_train.npy\", y_train)\n",
    "    np.save(notebook_dir / \"y_test.npy\", y_test)\n",
    "    \n",
    "    # Save minimalist metadata for loading script\n",
    "    metadata = {\n",
    "        'vocab': vocab,\n",
    "        'reverse_vocab': reverse_vocab,\n",
    "        'class_weights': {str(int(k)): float(v) for k, v in class_weights.items()},\n",
    "        'compatible_tools': {k: list(v) for k, v in compatible_tools.items()}\n",
    "    }\n",
    "    \n",
    "    with open(notebook_dir / \"processed_data.json\", \"w\") as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "        \n",
    "    print(f\"‚úÖ All processed data saved to: {notebook_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d63d5e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_results(history, output_dir):\n",
    "    \"\"\"Visualize and save training loss and metrics\"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    from pathlib import Path\n",
    "    plots_dir = Path(output_dir) / \"plots\"\n",
    "    plots_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(history['train_loss'], label='Train')\n",
    "    plt.plot(history['val_loss'], label='Val')\n",
    "    plt.title('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(plots_dir / \"training_curves.png\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca97fc49",
   "metadata": {},
   "source": [
    "## üèÜ SAVE ALL RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1108ee46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saving model to results/transformer_model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/henok/Desktop/Galaxy-GNN-XP-2/venv/lib/python3.10/site-packages/keras/src/saving/serialization_lib.py:405: UserWarning: The object being serialized includes a `lambda`. This is unsafe. In order to reload the object, you will have to pass `safe_mode=False` to the loading function. Please avoid using `lambda` in the future, and use named Python functions instead. This is the `lambda` being serialized:         loss=lambda y_true, y_pred: compute_weighted_loss_log_scaled(y_true, y_pred, class_weights),\n",
      "\n",
      "  return {key: serialize_keras_object(value) for key, value in obj.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model and metadata saved successfully!\n",
      "‚úÖ All processed data saved to: results/transformer_processed_data\n"
     ]
    }
   ],
   "source": [
    "RESULTS_DIR = 'results/'\n",
    "plot_training_results(history, RESULTS_DIR)\n",
    "\n",
    "save_complete_transformer_model(\n",
    "    model=model,\n",
    "    output_dir=RESULTS_DIR,\n",
    "    vocab=vocab,\n",
    "    reverse_vocab=reverse_vocab,\n",
    "    class_weights=class_weights,\n",
    "    compatible_tools=compatible_tools,\n",
    "    config={'embed_dim': 128, 'max_len': 25},\n",
    "    history=history\n",
    ")\n",
    "\n",
    "save_processed_data_for_notebook(\n",
    "    X_train, X_test, y_train, y_test, \n",
    "    vocab, reverse_vocab, class_weights, \n",
    "    compatible_tools, RESULTS_DIR\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d530192",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
